# Generative AI Papers   

### Reinforcement Learning and RFT
- TRPO: [Trust Region Policy Optimization](https://arxiv.org/pdf/1502.05477)
- PPO: [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347)
- PoT: [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/pdf/2211.12588)
- ToRA: [ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving](https://arxiv.org/abs/2309.17452)
- DPO: [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290)
- ORPO: [ORPO: Monolithic Preference Optimization without Reference Model](https://arxiv.org/pdf/2403.07691)
- [A comparison of Self-Play Algorithms Under a Generalized Framework](https://arxiv.org/pdf/2006.04471)
- DeepSeekMath with GRPO: [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300) -- [[notes](./papers/grpo.md)]
- DeepSeek-R1: [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)   
- DeepSeek-V3: [DeepSeek-V3 Technical Report](https://arxiv.org/pdf/2412.19437v1)   
- DeepSeek: [Inference-Time Scaling for Generalist Reward Modeling](https://arxiv.org/pdf/2504.02495)     
- DeepSeek: [Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures](https://www.arxiv.org/pdf/2505.09343)
- Llama4: [The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)
- DAPO: [DAPO: An Open-Source LLM Reinforcement LearningSystem at Scale](https://arxiv.org/pdf/2503.14476),[[repo](https://github.com/BytedTsinghua-SIA/DAPO)]


### LLM architecture 
- [Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation](https://arxiv.org/pdf/2507.10524)
- [A MAMBA FOUNDATION MODEL FOR TIME SERIES FORECASTING](https://arxiv.org/pdf/2411.02941)
- [Is Mamba Effective for Time Series Forecasting](https://arxiv.org/pdf/2411.02941)


### LLM reasoning    
- [Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications](https://arxiv.org/pdf/2502.04384)
- [Tracing the thoughts of a large language model](https://www.anthropic.com/research/tracing-thoughts-language-model) -- [[notes](https://www.linkedin.com/posts/yunfei-felix-bai-909b861_for-a-long-time-the-inner-workings-of-large-activity-7314371553020821504-7gNB?utm_source=share&utm_medium=member_desktop&rcm=ACoAAABaCZkBjRFlGTUWtb_PCnQmMW0bBukeXLw)]
- [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf)
- [The Illusion of the Illusion of Thinking](https://arxiv.org/pdf/2506.09250v1)
- [REASONING OR MEMORIZATION? UNRELIABLE RESULTS OF REINFORCEMENT LEARNING DUE TO DATA CONTAMINATION](https://arxiv.org/pdf/2507.10532)
- [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model](https://arxiv.org/pdf/2504.13837)


### Agentic AI
- [Cognitive Architectures for Language Agents](https://arxiv.org/pdf/2309.02427)
- [Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/pdf/2406.04692)
- [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442)
- [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/pdf/2309.07864)
- [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org/pdf/2504.19678)  
- [REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS](https://arxiv.org/pdf/2210.03629)  -- [[notes](./papers/react.md)]
- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366)  -- [[notes](./papers/reflexion.md)]
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761)
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent)  
- [Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/pdf/2503.13657)


### Deep Research Agent 
- [A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications](https://arxiv.org/pdf/2506.12594)
- [DEEP RESEARCH AGENTS: A SYSTEMATIC EXAMINATION AND ROADMAP](https://arxiv.org/pdf/2506.18096v1)
- [DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](https://arxiv.org/pdf/2504.03160)
- Research agent: [[notes](./papers/agentRxiv.md)]    
- [Agent Laboratory: Using LLM Agents as Research Assistants](https://arxiv.org/pdf/2501.04227)    
- [AgentRxiv: Towards Collaborative Autonomous Research](https://arxiv.org/pdf/2503.18102)    


### Agentic AI evaluation   
- [Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416)
- [GAIA benchmark of GenAI assistant](https://arxiv.org/pdf/2311.12983)  
- [THEAGENTCOMPANY: BENCHMARKING LLM AGENTS ON CONSEQUENTIAL REAL WORLD TASKS](https://arxiv.org/pdf/2412.14161)    


### Fine-tuning for Text2SQL and Text2Cypher
- [Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement](https://arxiv.org/abs/2410.01869)    
- [Aligning Large Language Models to a Domain-specific Graph Database](https://arxiv.org/html/2402.16567v1)
-  


