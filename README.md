# Generative AI Papers   

### LLM architecture 
- [Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation](https://arxiv.org/pdf/2507.10524)
- [Introducing Nested Learning: A new ML paradigm for continual learning](https://abehrouz.github.io/files/NL.pdf) | [summary](papers/Introducing_Nested_Learning.md)
- [DeepSeek-V3 architecture: mHC](https://arxiv.org/pdf/2512.24880) | [summary](papers/deepseek_mhc.md)
- [DeepSeek-V4 architecture: Engram](https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf)) | [summary](papers/deepseek_engram.md)       

2026     
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916)[summary](/papers/2205.11916v4.md)
- [The unreasonable effectiveness of pattern matching](https://arxiv.org/pdf/2601.11432v1)|[summary](/papers/2601.11432v1.md)
- [Recursive Language Models](https://arxiv.org/pdf/2512.24601v2)|[summary](/papers/2512.24601v2.md)
- [Self-Adapting Language Models](https://arxiv.org/pdf/2506.10943v2)|[summary](/papers/2506.10943v2.md)
- [CONTINUOUS AUTOREGRESSIVE LANGUAGE MODELS](https://arxiv.org/pdf/2510.27688v1)|[summary](/papers/2510.27688v1.md)
- [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/pdf/2601.11791v2)|[summary](/papers/2601.11791v2.md)
- [Can AI Recognize Its Own Reflection? Self-Detection Performance of LLMs in Computing Education](https://arxiv.org/pdf/2512.23587)|[summary](/papers/2512.23587v1.md)
- [Scaling Embedding Layers in Language Models](https://arxiv.org/pdf/2502.01637)|[summary](/papers/2502.01637v3.md)
- [Mining Generalizable Activation Functions](https://arxiv.org/pdf/2602.05688)|[summary](/papers/2602.05688v1.md)
- [DIRMOE: DIRICHLET-ROUTED MIXTURE OF EXPERTS](https://openreview.net/pdf?id=a15cDnzr6r)|[summary](/papers/11538_DirMoE_Dirichlet_Routed_.md)
- [Joint Embedding Variational Bayes](https://arxiv.org/pdf/2602.05639)|[summary](/papers/) ===>
- [LUCID: Attention with Preconditioned Representations](https://www.arxiv.org/pdf/2602.10410)|[summary](/papers/2602.10410v1.md)
- [ATTENTION SINKS AND COMPRESSION VALLEYS IN LLMS ARE TWO SIDES OF THE SAME COIN](https://arxiv.org/pdf/2510.06477)|[summary](/papers/2510.06477v2.md)
- [In-Context Learning Without Copying](https://arxiv.org/pdf/2511.05743)|[summary](/papers/2511.05743v2.md)
- [Discovering Differences in Strategic Behavior between Humans and LLMs](https://arxiv.org/pdf/2602.10324)|[summary](/papers/2602.10324v1.md)
- [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/pdf/2602.11748)|[summary](/papers/2602.11748v1.md)
- [Learning a Generative Meta-Model of LLM Activations](https://www.arxiv.org/pdf/2602.06964)|[summary](/papers/2602.06964v1.md)
- [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/pdf/2602.12005)|[summary](/papers/2602.12005v2.md)
- [Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models](https://arxiv.org/pdf/2602.08984)|[summary](/papers/2602.08984v1.md)
- [Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens](https://arxiv.org/pdf/2602.13517)|[summary](/papers/2602.13517v1.md)
- [Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?](https://arxiv.org/pdf/2602.07055)|[summary](/papers/2602.07055v1.md)
- [Attention, Please! Revisiting Attentive Probing Through the Lens of Efficiency](https://arxiv.org/pdf/2506.10178)|[summary](/papers/2506.10178v3.md)
- [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org/pdf/2505.06120)|[summary](/papers/2505.06120v1.md)
- [Intelligent AI Delegation](https://arxiv.org/pdf/2602.11865)|[summary](/papers/2602.11865v1.md)
- [Cartridges: Lightweight and general-purpose long context representations via self-study](https://arxiv.org/pdf/2506.06266)|[summary](/papers/2506.06266v3.md)
- [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/pdf/2509.01092)|[summary](/papers/2509.01092v2.md)
- [SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning](https://arxiv.org/pdf/2602.13515)|[summary](/papers/2602.13515v1.md)
- [LoopViT: Scaling Visual ARC with Looped Transformers](https://arxiv.org/pdf/2602.02156)|[summary](/papers/2602.02156v1.md)
- [Unified Latents (UL): How to train your latents](https://www.alphaxiv.org/overview/2602.17270)|[summary](/papers/Unified Latents (UL)_ How to train your latents.md)
- [Chatting with an LLM-based AI elicits affective and cognitive processes in education for sustainable development](https://www.nature.com/articles/s41598-026-39317-6)|[summary](/papers/s41598-026-39317-6.md)
- [Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability](https://arxiv.org/pdf/2601.18778)|[summary](/papers/2601.18778v2.md)
- [Scaling Embedding Layers in Language Models](https://arxiv.org/pdf/2502.01637)|[summary](/papers/2502.01637v3.md)
- [STATe-of-Thoughts: Structured Action Templates for Tree-of-Thoughts](https://arxiv.org/pdf/2602.14265) |[summary](/papers/2602.14265v1.md)
- [Towards a Principled Muon under μ\mathsf{P}: Ensuring Spectral Conditions throughout Training](https://arxiv.org/pdf/2601.01306)|[summary](/papers/2601.01306v2.md)
- [The Platonic Representation Hypothesis](https://arxiv.org/pdf/2405.07987)  |[summary](/papers/2405.07987v5.md)
- [Intelligent AI Delegation](https://arxiv.org/pdf/2602.11865) |[summary](/papers/2602.11865v1.md)


### Training, RL and RFT
- TRPO: [Trust Region Policy Optimization](https://arxiv.org/pdf/1502.05477)
- PPO: [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347)
- PoT: [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/pdf/2211.12588)
- ToRA: [ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving](https://arxiv.org/abs/2309.17452)
- DPO: [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290)
- ORPO: [ORPO: Monolithic Preference Optimization without Reference Model](https://arxiv.org/pdf/2403.07691)
- [A comparison of Self-Play Algorithms Under a Generalized Framework](https://arxiv.org/pdf/2006.04471)
- DeepSeekMath with GRPO: [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300) | [summary](papers/grpo.md)
- DeepSeek-R1: [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948) | [summary](papers/deepseek_r1_update2026.md)
- DeepSeek-V3: [DeepSeek-V3 Technical Report](https://arxiv.org/pdf/2412.19437v1)   
- DeepSeek: [Inference-Time Scaling for Generalist Reward Modeling](https://arxiv.org/pdf/2504.02495)     
- DeepSeek: [Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures](https://www.arxiv.org/pdf/2505.09343)
- Llama4: [The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)
- DAPO: [DAPO: An Open-Source LLM Reinforcement LearningSystem at Scale](https://arxiv.org/pdf/2503.14476) | [[repo](https://github.com/BytedTsinghua-SIA/DAPO)]
- RLVR-World: [RLVR-World: Training World Models with Reinforcement Learning](https://arxiv.org/abs/2505.13934) | [summary](papers/rlvr-world.md) | [[repo](https://github.com/thuml/RLVR-World)]
- SEAL: [Self-Adapting Language Models](https://arxiv.org/pdf/2506.10943) | [web](https://jyopari.github.io/posts/seal) | [code repo](https://github.com/Continual-Intelligence/SEAL) | ==> write its own training data, finetune itself, improve without human intervention

         
2026
- [Self-Distillation Enables Continual Learning](https://arxiv.org/abs/2601.19897)|[summary](/papers/2601.19897v1.md)
- [Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful](https://arxiv.org/pdf/2507.07101)|[summary](/papers/2507.07101v4.md)
- [The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination](https://arxiv.org/pdf/2601.08237)|[summary](/papers/2601.08237v1.md)
- [Learning to Reason without External Rewards](https://arxiv.org/pdf/2505.19590)|[summary](/papers/2505.19590v2.md)
- [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/pdf/2601.21343)|[summary](/papers/2601.21343v2.md)
- [RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](https://arxiv.org/pdf/2602.02488)|[summary](/papers/2602.02488v1.md)
- [Rethinking the Trust Region in LLM Reinforcement Learning](https://arxiv.org/pdf/2602.04879)|[summary](/papers/2602.04879v1.md)
- [Test-time Recursive Thinking: Self-Improvement without External Feedback](https://arxiv.org/pdf/2602.03094)|[summary](/papers/2602.03094v1.md)
- [Reinforced Attention Learning](https://arxiv.org/pdf/2602.04884)|[summary](/papers/2602.04884v2.md)
- [Privileged Information Distillation for Language Models](https://arxiv.org/pdf/2602.04942)|[summary](/papers/2602.04942v3,md)
- [FINE-TUNING WITH RAG FOR IMPROVING LLM LEARNING OF NEW SKILLS](https://arxiv.org/pdf/2510.01375)|[summary](/papers/2510.01375v1.md)
- [Rewards as Labels: Revisiting RLVR from a Classification Perspective](https://arxiv.org/pdf/2602.05630)|[summary](/papers/2602.05630v1.md)
- [Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks](https://arxiv.org/pdf/2602.05125)|[summary](/papers/2602.05125v1.md)
- [Maximum Likelihood Reinforcement Learning](https://arxiv.org/pdf/2602.02710)|[website](https://zanette-labs.github.io/MaxRL/)|[summary](/papers/) ===> 
- [RFS: Reinforcement Learning with Residual Flow Steering for Dexterous Manipulation](https://arxiv.org/pdf/2602.01789)|[website](https://entongsu.github.io/rfs/)|[summary](/papers/2602.01789v3.md)
- [Multi-Task GRPO: Reliable LLM Reasoning Across Tasks](https://arxiv.org/pdf/2602.05547)|[summary](/papers/2602.05547v1.md)
- [Experiential Reinforcement Learning](https://www.arxiv.org/pdf/2602.13949)|[summary](/papers/2602.13949v1.md)
- [Training-Free Group Relative Policy Optimization](https://arxiv.org/pdf/2510.08191)|[summary](/papers/2510.08191v1.md)
- [Embed-RL: Reinforcement Learning for Reasoning-Driven Multimodal Embeddings](https://arxiv.org/pdf/2602.13823)|[summary](/papers/2602.13823v2.md)
- [Learning to Reason in 13 Parameters](https://arxiv.org/pdf/2602.04118)|[summary](/papers/2602.04118v1.md)
- [Generative Reasoning Re-ranker](https://arxiv.org/pdf/2602.07774)|[summary](/papers/2602.07774v4.md)
- [SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning](https://arxiv.org/pdf/2602.08234)|[summary](/papers/2602.08234v1.md)
- [Reinforcement Learning via Self-Distillation](https://arxiv.org/pdf/2601.20802)|[summary](/papers/2601.20802v2.md)
- [Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability](https://arxiv.org/pdf/2601.18778)|[summary](/papers/2601.18778v2.md)
- [Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/pdf/2412.06769)|[summary](/papers/2412.06769v3.md)
- [iGRPO: Self-Feedback–Driven LLM Reasoning](https://arxiv.org/pdf/2602.09000)|[summary](/papers/2602.09000v1.md) 
- [Replicating Human Motivated Reasoning Studies with LLMs](https://arxiv.org/pdf/2601.16130)|[summary](/papers/2601.16130v1.md)
- [TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse](https://arxiv.org/pdf/2602.01439) | [code repo](https://github.com/pd-perry/TQL)|[summary](/papers/2602.01439v1.md) 
- [DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research](https://arxiv.org/pdf/2511.19399)|[summary](/papers/2511.19399v2.md)
- [CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use](https://arxiv.org/pdf/2602.12268)|[summary](/papers/2602.12268v2.md)
- [AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models](https://arxiv.org/pdf/2410.02355)|[summary](/papers/2410.02355v4.md)
- [The Magic Correlations: Understanding Knowledge Transfer from Pretraining to Supervised Fine-Tuning](https://arxiv.org/pdf/2602.11217)|[summary](/papers/2602.11217v1.md)
- [Intrinsic Credit Assignment for Long Horizon Interaction](https://www.alphaxiv.org/abs/intrinsic-credit-assignment)|[summary](/papers/IntrinsicCreditAssignmentforLongHorizonInteraction.md)
- [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/pdf/2601.06002)|[summary](/papers/2601.06002v2.md)
- [Learning Personalized Agents from Human Feedback](https://arxiv.org/pdf/2602.16173)|[summary](/papers/2602.16173v1.md)
- [Revisiting the Platonic Representation Hypothesis: An Aristotelian View](https://arxiv.org/pdf/2602.14486)|[summary](/papers/2602.14486v1.md)
- [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/pdf/2503.20783)|[summary](/papers/2503.20783v2.md)
- [On-Policy Context Distillation for Language Models](https://arxiv.org/pdf/2602.12275)|[summary](/papers/2602.12275v1.md)
- [Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains](https://arxiv.org/pdf/2507.17746)|[summary](/papers/2507.17746v2.md)
- [Robust Policy Optimization to Prevent Catastrophic Forgetting](https://arxiv.org/pdf/2602.08813)|[summary](/papers/2602.08813v1.md)
- [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/pdf/2601.18734)|[summary](/papers/2601.18734v1.md)
- [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/pdf/2601.18217)|[summary](/papers/2601.18217v1.md)
- [Generative Modeling via Drifting](https://arxiv.org/pdf/2602.04770)  |[summary](/papers/2602.04770v2.md)
- [Small Reward Models via Backward Inference](https://arxiv.org/pdf/2602.13551) |[summary](/papers/2602.13551v1.md)
- [CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models](https://arxiv.org/pdf/2602.17684) |[summary](/papers/2602.17684v1.md)
- [Learning Without Training](https://arxiv.org/pdf/2602.17985) |[summary](/papers/2602.17985v1.md)

### Interpretability
- [Anthropic:Tracing the Thoughts of a Large Language Model](https://www.anthropic.com/research/tracing-thoughts-language-model) | [summary](papers/ant_circuit_tracing_2.md)
- [Weight-sparse transformers have interpretable circuits](https://arxiv.org/pdf/2511.13653) | [summary](papers/openai_interpretable_circuit.md)
- [TensorLens: end-to-end transformer analysis via high-order attention tensors](https://www.alphaxiv.org/abs/2601.17958) | [summary](papers/TensorLens_End-to-EndTransformerAnalysisviaHigh-OrdeAttentionTensors.md)


### LLM reasoning    
- [Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications](https://arxiv.org/pdf/2502.04384)
- [Tracing the thoughts of a large language model](https://www.anthropic.com/research/tracing-thoughts-language-model) |[summary](https://www.linkedin.com/posts/yunfei-felix-bai-909b861_for-a-long-time-the-inner-workings-of-large-activity-7314371553020821504-7gNB?utm_source=share&utm_medium=member_desktop&rcm=ACoAAABaCZkBjRFlGTUWtb_PCnQmMW0bBukeXLw)
- [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf)
- [The Illusion of the Illusion of Thinking](https://arxiv.org/pdf/2506.09250v1)
- [REASONING OR MEMORIZATION? UNRELIABLE RESULTS OF REINFORCEMENT LEARNING DUE TO DATA CONTAMINATION](https://arxiv.org/pdf/2507.10532)
- [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model](https://arxiv.org/pdf/2504.13837)
- [Chain of Thought Monitorability](https://tomekkorbak.com/cot-monitorability-is-a-fragile-opportunity/cot_monitoring.pdf)
- [Training a Generally Curious Agent](https://arxiv.org/pdf/2502.17543)      
2026      
- [Large Language Model Reasoning Failures](https://www.arxiv.org/pdf/2602.06176) |[summary](papers/2602.06176v1.md)|[list of papers](https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures) 
- [LLMs are zero-shot reasoners](https://arxiv.org/pdf/2205.11916v4) | [summary](papers/2205.11916v4.md)
- [Prompt repetition improves non-reasoning LLMs](https://arxiv.org/pdf/2512.14982v1)|[summary](papers/2512.14982v1.md)
- [Reasoning Models Generate Societies of Thought](https://arxiv.org/pdf/2601.10825v1)|[summary](papers/2601.10825v1.md)
- [Agentic Reasoning for Large Language Models](https://arxiv.org/pdf/2601.12538v1)|[summary](papers/2601.12538v1.md)
- [Multiplex Thinking:Reasoning via Token-wise Branch-and-Merge](https://arxiv.org/pdf/2601.08808v1)|[summary](papers/2601.08808v1.md)
- [Thinking—Fast, Slow, and Artificial: How AI is Reshaping Human Reasoning and the Rise of Cognitive Surrender]([https://papers.ssrn.com/sol3/Delivery.cfm/6097646.pdf?abstractid=6097646&mirid=1)|[summary](papers/ssrn-6097646.md)
- [Training Large Language Models to Reasonina Continuous Latent Space](https://arxiv.org/pdf/2412.06769)[summary](papers/2412.06769v3.md)
- [Does Your Reasoning Model Implicitly Know When to Stop Thinking?](https://arxiv.org/pdf/2602.08354) | [[summary](papers/2602.08354v2.md)]


### Agentic AI
- [Cognitive Architectures for Language Agents](https://arxiv.org/pdf/2309.02427)
- [Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/pdf/2406.04692)
- [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442)
- [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/pdf/2309.07864)
- [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org/pdf/2504.19678)  
- [REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS](https://arxiv.org/pdf/2210.03629)  | [[summary](papers/react.md)]
- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366) | [summary](./papers/reflexion.md)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761)
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent)  
- [Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/pdf/2503.13657) | [code repo and dataset](https://github.com/multi-agent-systems-failure-taxonomy/MAST)
- [Kimi K2: Open Agentic Intelligence](https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf)

2026
- [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/pdf/2601.14192) | [summary](papers/2601.14192v1.md)
- [Grounding Agent Memory in Contextual Intent](https://arxiv.org/pdf/2601.10702) | [summary](papers/2601.10702v1.md)
- [A Large-Scale Study on the Development and Issues of Multi-Agent AI Systems](https://arxiv.org/pdf/2601.07136)  | [summary](papers/2601.07136v1.md)
- [https://arxiv.org/pdf/2601.07711](https://arxiv.org/pdf/2601.07711)  | [summary](papers/2601.07711v1.md)
- [Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale](https://arxiv.org/pdf/2601.10338) | [summary](papers/2601.10338v1.md)
- [Scaling Small Agents Through Strategy Auctions](https://arxiv.org/pdf/2602.02751) | [summary](papers/2602.02751v1.md)
- [SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks](https://arxiv.org/pdf/2602.12670) | [summary](papers/2602.12670v1.md)
- [Let It Flow: Agentic Crafting on Rock and Roll - Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/pdf/2512.24873) | [summary](papers/2512.24873v2.md)
- [Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents](https://arxiv.org/pdf/2510.24702) | [summary](papers/2510.24702v1.md)
- [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/pdf/2602.12662) | [summary](papers/2602.12662v1.md)
- [When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail](https://arxiv.org/pdf/2601.04748) | [summary](papers/.md)
- [Agents of Chaos](https://arxiv.org/pdf/2602.20021) | [summary](papers/2602.20021v1.md)
- [Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models](https://arxiv.org/pdf/2510.04618)| [summary](papers/2510.04618v2.md)

### Deep Research Agent 
- [A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications](https://arxiv.org/pdf/2506.12594)
- [DEEP RESEARCH AGENTS: A SYSTEMATIC EXAMINATION AND ROADMAP](https://arxiv.org/pdf/2506.18096v1)
- [A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges](https://arxiv.org/pdf/2508.05668)
- [DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](https://arxiv.org/pdf/2504.03160)
- Research agent: [[notes](./papers/agentRxiv.md)]    
- [Agent Laboratory: Using LLM Agents as Research Assistants](https://arxiv.org/pdf/2501.04227)    
- [AgentRxiv: Towards Collaborative Autonomous Research](https://arxiv.org/pdf/2503.18102)    


### Coding Agent 
- [From Code Foundation Models to Agents and Applications: A Comprehensive Survey and Practical Guide to Code Intelligence](https://arxiv.org/pdf/2511.18538)


### Agentic AI evaluation   
- [Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416)
- [GAIA benchmark of GenAI assistant](https://arxiv.org/pdf/2311.12983)  
- [THEAGENTCOMPANY: BENCHMARKING LLM AGENTS ON CONSEQUENTIAL REAL WORLD TASKS](https://arxiv.org/pdf/2412.14161)     
- [Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey](https://arxiv.org/abs/2503.22458)    
- [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](https://arxiv.org/abs/2503.01935)    
- [Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications](https://arxiv.org/abs/2412.05449)    


### Vertical LLMs and Agents
- [MedGemma Technical Report](https://arxiv.org/pdf/2507.05201)
- [Mapping the susceptibility of large language models to medical misinformation acrossclinical notes and social media: a cross-sectional benchmarking analysis](https://www.thelancet.com/action/showPdf?pii=S2589-7500%2825%2900131-1)  ==> AI not working for medical advice


### Large World Model (LWM) 
- [A MAMBA FOUNDATION MODEL FOR TIME SERIES FORECASTING](https://arxiv.org/pdf/2411.02941)
- [Is Mamba Effective for Time Series Forecasting](https://arxiv.org/pdf/2411.02941)
- [From Words to Worlds: Spatial Intelligence is AI’s Next Frontier](https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence)    
- [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243)    
- [V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/abs/2506.09985)
- [ATTENTION SINKS AND COMPRESSION VALLEYS IN LLMS ARE TWO SIDES OF THE SAME COIN](https://arxiv.org/pdf/2510.06477)  ===> why transformers fail     

2026     
- [Statistical approximation is not general intelligence](https://www.nature.com/articles/d41586-026-00495-y) | [summary](papers/Statistical-approximation_is_not_general_intelligence.md)
- [Do generative video models understand physical principles?](https://arxiv.org/pdf/2501.09038) | [summary](papers/2501.09038v3.md)
- [LLM-JEPA: Large Language Models Meet Joint Embedding Predictive Architectures](https://arxiv.org/pdf/2509.14252) | [summary](papers/2509.14252v2.md)
- [Tiny Recursive Reasoning with Mamba-2 Attention Hybrid](https://arxiv.org/pdf/2602.12078) | [summary](papers/2602.12078v1.md)
- [Cold-Start Personalization via Training-Free Priors from Structured World Models](https://arxiv.org/pdf/2602.15012) | [summary](papers/2602.15012v1.md)
- [Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control](https://arxiv.org/pdf/2602.13193) | [website](https://steerable-policies.github.io/)  | [summary](papers/2602.13193v1.md)

### Multi-modality
- [ViT-5: Vision Transformers for The Mid-2020s](https://www.arxiv.org/pdf/2602.08071) | [code repo](https://github.com/wangf3014/ViT-5) ==> new vision transformer model



### Fine-tuning Text2SQL and Text2Cypher
- [Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement](https://arxiv.org/abs/2410.01869)    
- [Aligning Large Language Models to a Domain-specific Graph Database](https://arxiv.org/html/2402.16567v1)



