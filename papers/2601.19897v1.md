The provided text appears to be a technical document discussing machine learning model training methodologies, specifically comparing **Supervised Fine-tuning (SFT)**, **Dense Fine-tuning (DFT)**, and **Self-Distillation Fine-tuning (SDFT)**. Below is a structured summary of the key insights and findings:

---

### **Key Concepts and Methodologies**
1. **SFT (Supervised Fine-tuning)**:
   - Traditional approach where models are fine-tuned on labeled data using supervised learning.
   - Uses standard hyperparameters (e.g., learning rate, optimizer, batch size).
   - Performance is limited by the quality and quantity of labeled data.

2. **DFT (Dense Fine-tuning)**:
   - Likely a variant of fine-tuning with denser training strategies (e.g., more frequent updates or parameter adjustments).
   - Results show moderate performance across tasks but underperforms SDFT in most cases.

3. **SDFT (Self-Distillation Fine-tuning)**:
   - A novel approach combining **self-distillation** (knowledge distillation from the model itself) and **fine-tuning**.
   - Uses **Exponential Moving Average (EMA)** for teacher model updates (controlled by hyperparameter `α`).
   - Incorporates **on-policy student rollouts** and **teacher log-probability computations** during training.
   - Key hyperparameters: `α` (EMA rate), max generation length (2048 for Skill Learning, 1024 for Knowledge Acquisition).

---

### **Performance Results**
The tables (Table 5) compare the **new-task accuracy** and **average prior-task performance** across three domains: **Skill Learning**, **Tool Use**, and **Medical**. Here are the critical observations:

#### **Skill Learning Tasks**
| Method         | New Task Accuracy | Prior Task Avg. |
|----------------|-------------------|------------------|
| **SDFT (Ours)**| **70.2**          | **64.5**         |
| SFT            | 66.2              | 53.4             |
| DFT            | 54.8              | 60.2             |
| Base Model     | 32.1              | **65.5**         |

- **SDFT outperforms all methods** in both new-task accuracy and prior-task retention.
- The **base model** (without fine-tuning) achieves strong prior-task performance but struggles with new tasks.
- **SFT + re-invoke** (a hybrid approach) performs moderately but is outperformed by SDFT.

#### **Tool Use Tasks**
| Method         | New Task Accuracy | Prior Task Avg. |
|----------------|-------------------|------------------|
| **SDFT (Ours)**| **70.6**          | **65.4**         |
| DFT            | 64.2              | 60.8             |
| SFT + re-invoke| 63.1              | 63.7             |
| Base Model     | 42.9              | **65.5**         |

- SDFT again leads in new-task accuracy while maintaining strong prior-task performance.
- The **base model** retains prior knowledge but fails to adapt to new tasks.

#### **Medical Tasks**
| Method         | New Task Accuracy | Prior Task Avg. |
|----------------|-------------------|------------------|
| **SDFT (Ours)**| **40.2**          | **65.4**         |
| DFT            | 36.2              | 64.0             |
| SFT + re-invoke| 35.6              | 62.6             |
| Base Model     | 30.1              | **65.5**         |

- SDFT achieves the highest new-task accuracy in medical tasks, suggesting robust generalization.
- The **base model** retains prior knowledge but struggles with new, complex tasks.

---

### **Hyperparameter Sweeps**
- **SDFT-only hyperparameters**:
  - **EMA rate (α)**: {0.01, 0.02, 0.05} (higher α improves stability but may reduce adaptability).
  - **Max generation length**: 2048 (Skill Learning) / 1024 (Knowledge Acquisition).
- **Shared hyperparameters**:
  - Learning rate: {5e-6, 1e-5, 5e-5}
  - Optimizer: `adamw` with cosine warmup scheduling.
  - Batch size: {16, 32, 64} (no batch size for CPT in Knowledge Acquisition).

---

### **Key Takeaways**
1. **SDFT excels in multi-task learning** by combining self-distillation and fine-tuning, achieving superior performance on new tasks while retaining prior knowledge.
2. **Self-distillation** (via EMA) helps stabilize training and improve generalization.
3. **SFT and DFT** are outperformed by SDFT, highlighting the benefits of incorporating distillation in fine-tuning.
4. **The base model** retains prior-task performance but lacks adaptability to new tasks, emphasizing the need for active learning strategies.

---

### **Implications**
- **SDFT is ideal for scenarios** requiring adaptability to new tasks while preserving prior knowledge (e.g., continual learning, multi-task systems).
- The **EMA rate (α)** and **generation length** are critical hyperparameters for balancing stability and adaptability.
- Future work could explore **domain-specific EMA tuning** or **dynamic generation length adjustments** for different task types.

Let me know if you need further clarification on specific sections or want to analyze the methodology in detail!

===============

## 中文翻译

提供的文本似乎是一份技术文档，讨论机器学习模型训练方法，具体比较了**监督微调（SFT）**、**密集微调（DFT）**和**自蒸馏微调（SDFT）**。以下是关键见解和发现的结构化摘要：

---

### **关键概念和方法**
1. **SFT（监督微调）**：
   - 传统方法，通过监督学习在带标签数据上进行微调。
   - 使用标准超参数（例如学习率、优化器、批量大小）。
   - 性能受限于带标签数据的质量和数量。

2. **DFT（密集微调）**：
   - 可能是采用更密集训练策略（例如更频繁的更新或参数调整）的微调变体。
   - 结果显示在任务中表现中等，但大多数情况下表现不如SDFT。

3. **SDFT（自蒸馏微调）**：
   - 一种结合**自蒸馏**（从模型自身进行知识蒸馏）和**微调**的新方法。
   - 使用**指数移动平均（EMA）**更新教师模型（由超参数`α`控制）。
   - 在训练过程中结合**基于策略的学生回放**和**教师对数概率计算**。
   - 关键超参数：`α`（EMA率）、最大生成长度（技能学习为2048，知识获取为1024）。

---

### **性能结果**
表格（表5）比较了**新任务准确率**和**平均先前任务表现**在三个领域：**技能学习**、**工具使用**和**医疗**中的表现。以下是关键观察：

#### **技能学习任务**
| 方法         | 新任务准确率 | 先前任务平均 |
|----------------|----------------|------------------|
| **SDFT（我们方法）**| **70.2**      | **64.5**         |
| SFT           | 66.2          | 53.4             |
| DFT           | 54.8          | 60.2             |
| 基础模型      | 32.1          | **65.5**         |

- **SDFT在新任务准确率和先前任务保留方面均优于所有方法**。
- **基础模型**（未经微调）在先前任务表现上较强，但在新任务上表现不佳。
- **SFT + 重新调用**（混合方法）表现中等，但被SDFT超越。

#### **工具使用任务**
| 方法         | 新任务准确率 | 先前任务平均 |
|----------------|----------------|------------------|
| **SDFT（我们方法）**| **70.6**      | **65.4**         |
| DFT           | 64.2          | 60.8             |
| SFT + 重新调用| 63.1          | 63.7             |
| 基础模型      | 42.9          | **65.5**         |

- SDFT在新任务准确率上再次领先，同时保持较强的先前任务表现。
- **基础模型**保留了先前知识，但无法适应新任务。

#### **医疗任务**
| 方法         | 新任务准确率 | 先前任务平均 |
|----------------|----------------|------------------|
| **SDFT（我们方法）**| **40.2**      | **65.4**         |
| DFT           | 36.2          | 64.0             |
| SFT + 重新调用| 35.6          | 62.6             |
| 基础模型      | 30.1          | **65.5**         |

- SDFT在医疗任务中实现了最高的新任务准确率，表明其具备良好的泛化能力。
- **基础模型**保留了先前知识，但在新且复杂的任务上表现不佳。

---

### **超参数扫描**
- **SDFT专用超参数**：
  - **EMA率（α）**：{0.01, 0.02, 0.05}（较高的α提升稳定性，但可能降低适应性）。
  - **最大生成长度**：2048（技能学习）/ 1024（知识获取）。
- **共享超参数**：
  - 学习率：{5e-6, 1e-5, 5e-5}
  - 优化器：`adamw`搭配余弦预热调度。
  - 批量大小：{16, 32, 64}（知识获取中CPT无批量大小）。

---

### **关键结论**
1. **SDFT通过结合自蒸馏和微调，在多任务学习中表现出色**，在新任务上实现卓越性能，同时保留先前知识。
2. **自蒸馏**（通过EMA）有助于稳定训练并提升泛化能力。
3. **SFT和DFT被SDFT超越，突显了在微调中引入蒸馏方法的优势**。
4. **基础模型**保留了先前任务表现，但缺乏对新任务的适应性，强调了主动学习策略的必要性。

---

### **启示**
- **SDFT适用于需要适应新任务同时保留先前知识的场景**（例如持续学习、多任务系统）。
- **EMA率（α）**和**生成长度**是平衡稳定性和适应性的关键超参数。
- 未来工作可探索**领域特定的EMA调优**或**针对不同任务类型的动态生成长度调整**。

如需进一步澄清特定部分或分析方法细节，请告知！

#### Reference: 

Source file: 2601.19897v1.pdf

---

**Title**: SELF-DISTILLATION ENABLES CONTINUAL LEARNING
