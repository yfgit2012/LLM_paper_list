The provided text outlines a framework for **rubric decomposition and filtering** to evaluate responses based on specific criteria. Here's a breakdown of the key components and their purpose:

---

### **Core Concepts**
1. **Rubric Generation**:
   - **Goal**: Create granular, discriminative criteria to assess response quality.
   - **Inputs**: 
     - User prompt (e.g., "Explain quantum computing").
     - Reference responses (examples of good/bad answers).
   - **Output**: A set of rubrics (e.g., "Mentions key principles like superposition and entanglement").

2. **Rubric Refinement**:
   - **Goal**: Improve existing rubrics by splitting them into more specific criteria.
   - **Inputs**: 
     - Existing rubric (e.g., "Is comprehensive").
     - Other rubrics to avoid overlap.
   - **Output**: Two new, more granular rubrics (e.g., "Addresses edge cases" and "Justifies technical terms").

3. **Filtering Rubrics**:
   - **Overlap Check**: Ensures new rubrics don’t duplicate existing ones (e.g., "Avoids redundancy with 'Is comprehensive'").
   - **Conflict Check**: Prevents contradictory rubrics (e.g., "Must include X" vs. "Must exclude X").

4. **Evaluation**:
   - **Judgment**: Determines if a response meets a rubric's criteria (e.g., "Does the response explicitly mention superposition?").

---

### **Workflow Example**
1. **Initial Rubric Generation**:
   - **Prompt**: "Explain quantum computing."
   - **Reference Responses**: 
     - Good: "Quantum computing uses qubits, which can be in superposition..."
     - Bad: "It's a type of computing that uses quantum mechanics."
   - **Output Rubrics**:
     - `<RUBRIC> Mentions key principles like superposition and entanglement </RUBRIC>`
     - `<RUBRIC> Avoids vague descriptions </RUBRIC>`

2. **Refinement**:
   - **Existing Rubric**: "Is comprehensive."
   - **New Rubrics**:
     - `<RUBRIC> Addresses edge cases (e.g., quantum decoherence) </RUBRIC>`
     - `<RUBRIC> Justifies technical terms (e.g., defines 'qubit') </RUBRIC>`

3. **Filtering**:
   - **Check Overlap**: Ensure new rubrics don’t overlap with existing ones.
   - **Check Conflict**: Avoid contradictory criteria (e.g., "Must include citations" vs. "Avoid citations").

4. **Evaluation**:
   - **Response**: "Quantum computing leverages qubits, which can exist in superposition states."
   - **Rubric**: "Mentions key principles like superposition and entanglement."
   - **Judgment**: `<EVALUATION> YES </EVALUATION>`

---

### **Key Takeaways**
- **Granularity**: Rubrics must be specific to differentiate high-quality responses.
- **Avoid Redundancy**: Ensure new rubrics add unique value.
- **Consistency**: Rubrics must be objective and verifiable without external knowledge.
- **Automation**: The framework supports tools for auto-generating, refining, and validating rubrics.

This approach enhances evaluation by breaking down complex tasks into measurable criteria, ensuring fairness and precision in assessing responses.

===============

## 中文翻译

### **核心概念**
1. **评分标准生成**：
   - **目标**：创建细致且具有区分度的标准以评估回答质量。
   - **输入**：
     - 用户提示（例如：“解释量子计算”）。
     - 参考回答（优质或劣质回答的示例）。
   - **输出**：一组评分标准（例如：“提及叠加态和纠缠等关键原理”）。

2. **评分标准优化**：
   - **目标**：通过将现有评分标准拆分为更具体的条目来改进评分标准。
   - **输入**：
     - 现有评分标准（例如：“内容全面”）。
     - 其他评分标准以避免重复。
   - **输出**：两个更细致的评分标准（例如：“涵盖边缘案例”和“解释技术术语”）。

3. **评分标准筛选**：
   - **重叠检查**：确保新评分标准不与现有标准重复（例如：“避免与‘内容全面’重复”）。
   - **冲突检查**：防止矛盾的评分标准（例如：“必须包含引用” vs. “必须避免引用”）。

4. **评估**：
   - **判断**：确定回答是否符合评分标准的条件（例如：“回答是否明确提及叠加态？”）。

---

### **工作流程示例**
1. **初始评分标准生成**：
   - **提示**：“解释量子计算”。
   - **参考回答**：
     - 优质回答：“量子计算使用量子比特，它可以处于叠加态……”。
     - 劣质回答：“它是一种利用量子力学的计算方式”。
   - **输出评分标准**：
     - `<RUBRIC> 提及叠加态和纠缠等关键原理 </RUBRIC>`。
     - `<RUBRIC> 避免模糊描述 </RUBRIC>`。

2. **优化**：
   - **现有评分标准**：“内容全面”。
   - **新增评分标准**：
     - `<RUBRIC> 涵盖边缘案例（如量子退相干） </RUBRIC>`。
     - `<RUBRIC> 解释技术术语（如定义‘量子比特’） </RUBRIC>`。

3. **筛选**：
   - **检查重叠**：确保新评分标准不与现有标准重复。
   - **检查冲突**：避免矛盾的标准（例如：“必须包含引用” vs. “必须避免引用”）。

4. **评估**：
   - **回答**：“量子计算利用量子比特，它可以处于叠加态。”。
   - **评分标准**：“提及叠加态和纠缠等关键原理。”。
   - **判断**：`<EVALUATION> YES </EVALUATION>`。

---

### **关键要点**
- **细致性**：评分标准必须具体以区分高质量回答。
- **避免冗余**：确保新增评分标准具有独特价值。
- **一致性**：评分标准必须客观且可验证，无需外部知识。
- **自动化**：该框架支持自动生成、优化和验证评分标准的工具。

此方法通过将复杂任务分解为可衡量的标准，提升评估的公平性和精确性。

#### Reference: 

Source file: 2602.05125v1.pdf

---

**Title**: !(paper_images/2602.05125v1.pdf-0-0.png)
