## Definition of AGI
* AGI is an intelligent system capable of performing tasks that typically require human cognition.  [2]
* The hallmark of AGI is its ability to self-evolve, such as models transitioning from GPT-4 to GPT-5 without human intervention, or achieving self-awareness akin to humans (e.g., evolving from being amused by jokes to creating them). [14]
* AGI definition framework proposed by Yoshua Bengio’s team, based on CHC theory (cognitive ability classification) [11] –  through quantifiable metrics: ten dimensions (e.g., long-term memory, immediate reasoning, visual processing) and quantitatively assessing model performance.
* AGI possess the ability to learn and adapt to the environment autonomously, akin to animals or humans acquiring knowledge through direct interaction with the world. [17]
* AGI possess structured modeling capabilities for the physical world, causal relationships, and social rules, rather than relying solely on linguistic symbols. [17]
* AGI's ultimate goal is to create intelligent agents capable of understanding, predicting, and acting in the world. World Models are key to achieving this goal.  [18]



## Vision of AGI and future outlook 
* AGI should have the ability to understand common sense, learn new skills, and handle daily challenges, replace repetitive, standardized work
* AGI should learn human aesthetics, imagery, and deep thinking (e.g., poetry creation).
* AGI should draw from biological mechanisms (e.g., value function) to enhance intelligence [9]
* AGI should possess the ability to “create new concepts,” such as Einstein proposing special relativity or designing entirely new game rules, rather than merely optimizing within existing frameworks. [12]
* AGI should be pursuing Einstein-level creativity - disrupt traditional professions (e.g., doctors, lawyers), meantime solve global challenges (e.g., cancer, climate change) by replicating top experts’ wisdom.
* Future multipolar AGI world: AI will differentiate into systems specialized in distinct domains (e.g., research, law), forming a decentralized collaborative ecosystem, but caution is needed regarding the “window period” when AI capabilities exceed human ones. [9]
From Experience to Infinity: Through cyclic mechanisms, agents can self-improve, ultimately achieving open superintelligence (AGI). [20]
* Mechanistic Answer: The nature of Intelligence is an eternal cycle of self-driven, self-creative, and self-improving evolution.  [20] 
* Scientific and Artistic Golden Age: Achieving AGI could drive scientific breakthroughs (e.g., curing cancer) and artistic innovation (universal creation). [12]
* AGI development should take human intuition, moral judgment, and understanding of the world into consideration 
* AGI basic research should be based on cognition + perception, pursuing technological breakthroughs and the essence of intelligence. Only diverse perspectives and open exploration can prevent the industry from falling into path dependence, and world models may become the key to achieving truly intelligent agents. [18]
* Last, whether AI possesses consciousness remains an unresolved mystery (for example emotional expression). This leads to legal framework update, education system reform, social distribution mechanisms adjust.  



## Projected timeline of AGI 
There are differernt opinions 
* AGI may be achieved by 2028, or occur “suddenly in the coming years”, replacing human intellectual labor is one hand, unleashing creativity to propel society toward an “abundance” era. is more important 
* AGI may take a decade, the notion of “rapid AI iteration,” may not be realistic due to that critical systems (e.g., autonomous driving, healthcare) cannot afford trial-and-error costs and require rigorous testing and validation. [9]
* AGI major breakthroughs may occur within the next 5-10 years, specialized capabilities in specific domains (e.g., customer service, coding), but requires “continuing the trend.”
* DeepMind estimates AGI will be achieved within 5-10 years, requiring 1-2 foundational breakthroughs, such as “continual learning” (learning new knowledge without retraining) or “cross-domain reasoning.”  [12]
* AGI needs to achieve “perceptual intelligence → cognitive intelligence → general intelligence,”  requiring foundational scientific breakthroughs, which may take decades.
* AGI may enable machines to outperform humans in debates within 20 years



## Can LLMs be the correct direction toward AGI: current limitation 
The AI field remains vibrant, with diverse viewpoints driving rational development. [16]         
It's controversy over whether large language models can achieve AGI. [11]      
(a) Industry leaders (such as OpenAI and Google) believe large language models have potential    
(b) Academic community (such as Sutton, Marcus, and LeCun) points out their core flaws.      
The limitations include    
* ordinary people’s lives have not significantly changed -  limitations of AI models in complex economic activities. [9]
* Vibe coding “modify → new bug → re-modify → back to the original point” due to  insufficient reasoning capabilities [9]
* Current AI resembles “cramming” students rather than “gifted” learners. [9]
* Current LLM approach has issues such as long-term memory loss, inadequate reasoning ability, and defects in multimodal understanding. [11]
* “capability distortion,” where models mask fundamental flaws through technical means (such as working memory expansion or external search), creating a false illusion of general intelligence. [11]
GPT-5 only scores 58% with the following limitation [11]
(a) Long-term Memory Deficiency: Unable to accumulate experience or correct errors, requiring cold starts for each conversation.
(b) Inadequate Reasoning Ability: Unable to adapt to rule changes (e.g., Wisconsin Card Sorting Test), lacking metacognitive capabilities.
(c) Multimodal Understanding Defects: Unable to perform complex visual reasoning (e.g., spatial scanning) or in-depth auditory analysis (e.g., phoneme coding).
* Current AI Shortcomings: Unable to autonomously propose new theories or cross-domain analogies (e.g., deriving physics problems from biology). [12]     
* AI’s Auxiliary Nature: Enhances efficiency (10-100x), but cannot replace human narrative skills or artistic styles.    
* Current LLM is lack of world model [17]
(a) LLMs are merely “describers” of language, not “understanders” of the world. They cannot interact with the physical world through perception-action-reward loops (perception-action-reward loops), thus failing to form a structured understanding of the world like animals or humans.
(b) This “embodied intelligence” is key to building a world model, which LLMs lack due to their absence of physical senses.
(c) intelligent systems must learn through trial and feedback (perception-action-reward loops), whereas LLMs rely on static text data,
(d) LLMs’ generative models (token-by-token generation) cannot capture the essence of the world,
(e) a system without goals is not intelligent, LLM lack clear goals and the ability to actively pursue them
(f) intelligent systems must possess hierarchical planning and abstract prediction capabilities 
(g) mechanism of autonomous learning as the core of intelligence.
(h) embodied intelligence (direct interaction between body and environment) and self-supervised learning (extracting abstract laws from data).
(i) Large language models perform poorly in handling continuous, high-dimensional, and noisy data (such as video and physical perception), while Silicon Valley’s “compute + data” competition may hinder the birth of truly breakthrough technologies.
* Current AI resembles “cramming” students rather than “gifted” learners. (pre-training and RL)  [9]
* Current AI lack of visual reasoning and long-term memory management. - to understand the world’s operational principles
* Current AI models generate “AI Slop” (lengthy, format-heavy, and content-poor) due to overemphasis on ranking metrics (e.g., Chatbot Arena).
* Currently LLM models optimize for user engagement rather than productivity.
* Contrasts human and AI learning mechanisms, AGI should emphasizing the importance of “value function” and “prior knowledge,” versus the industry’s over-reliance on computational power. [9]
* Safety and ethical are one of the main concerns - behavior aligns with human values to prevent deceptive or utilitarian strategies due to excessive intelligence. - using CoT monitoring 
* Current AI has surpassed humans in image recognition and language translation but lacks “human traits” like cultural understanding.





## Technical and ethical challenges towards AGI 
* AI development transitions from mere scaling of computational power to smarter algorithm research ⇒ imbalance between scaling (Scaling Era) and innovation (Exploration Era), as well as the indivisibility of safety and capability.  [9]
* reinforcement learning and experience loops,   the evolution of goal-driven intelligence.[19]
* self-supervised learning and abstract modeling intelligent systems through hierarchical planning and world models. [19]
* Continual Learning  [20]   
(a) Catastrophic Forgetting: Deep neural networks struggle to learn new knowledge continuously without losing old knowledge during runtime.    
(b) Current Status: No reliable algorithms exist, especially for nonlinear function approximators (e.g., deep networks).     
* Meta-Learning of New Features   [20]    
(a) New Term Problem: How to generate useful features from scratch?     
(b) Current Status: Relies on heuristic generation and testing, lacking efficient, creative feature generators.     
* Deep meaning of AI safety: Safety requires ensuring alignment with human values before AI surpasses human capabilities, not merely through rule-based constraints. [9]    
* AI still has breakthrough potential in spatial intelligence and multimodal interaction, and warns against over-concentration on large language models. [16]
* Without technological breakthroughs, AI would become a “castle in the air”; however, path dependency (e.g., focusing solely on scaling parameters) must be avoided. → blindly scaling parameter sizes), which may waste resources. [16] ⇒ vs breakthroughs in spatial intelligence, causal reasoning, and other foundational scientific problems
* Current AI lacks cultural mechanisms, requiring multi-Agent systems for knowledge sharing and collaborative evolution, but only if individual Agents reach “adult-level” capabilities. [9]



## Current progress of Generative AI (LLM) application  
Currently AI has already reached human-level performance in rule-based, repetitive domains (e.g., customer service, data entry), and AI itself can accelerate iteration [16]     
2025 marked a pivotal year for Genrative AI.         
* Transforming to more integral, user-centric infrastructure.
* LLM driven to Agent driven: 
* Visual interaction with Multimodal-LLM 
* Local AI agent and customized AI agents 

In the past 5 years, LLM brings benefits:     
* healthcare more equitable (medical knowledge sharing and personal health management)
* education more accessible (Democratization of Knowledge Acquisition), and work more efficient  
* lower information access barriers, stimulating collective wisdom and creativity.   

### Local agent: 
shift from cloud-based services to “resident AI agents” transformed LLMs into proactive, on-demand assistants. Democratization of Programming

### Coding agent Dominates Development Processes: 
* Claude code, Cursor, Cline, OpenAI codex, Github copilot, AWS Kiro + open-source tools 
* Impact to programmers: offloading repetitive tasks to AI, focusing on innovation and system design. - smaller team, more personalized 
* AI as a team member 

### Research agent:  
cross-source information integration, and technical document retrieval. 

### Custom agents:   
Scenario-Specific Customization:  “agentifying everything” - Enterprises build internal agents (multiple use cases) for complex business scenarios, 
* still early stage
* Evaluation: open-ended interaction of AI agents still rely on human review 
* alancing cost and compliance 

### Healthcare Field
* Drug Development: Isomorphic uses AI to predict compound side effects, accelerating cancer and immunology drug development.
* Personalized Medicine: AI aids in designing targeted treatment plans, shortening R&D cycles.

### Art and Entertainment
Co-Creation Era: Users can generate personalized content (e.g., David Matthews-style music, Braveheart-inspired games), with top creators transitioning to “worldview editors,” designing core narrative frameworks.

### Energy and Environment   
AI’s Dual-Edged Sword: Short-term energy consumption growth (training large models), but long-term potential is vast (optimizing grids, designing efficient solar panels, enhancing wind power efficiency), becoming a key tool for addressing climate change.


## Generative AI and LLM short term evolution in 2026 
* driving complex data processing in fields like materials science and biology. [8]
* shifting toward algorithmic optimization (e.g., more efficient inference mechanisms, more sparse model designs.). [8]
* SaaS Architecture Reconstruction: AI dynamically generates business logic via Agents, replacing traditional three-tier coupled structures.  [7]
* AI Agent Explosion, retail, ads, independently complete scientific discoveries (from hypothesis to paper publication).    [5]
* Open source → [19]     
(a) Advantages of Open Source: Global collaboration accelerates innovation (e.g., DeepSeek, ResNet paper), reduces R&D costs, and enhances safety. 
(b) Open Ecosystem: Breaks down geographical and institutional barriers, gathering global wisdom to drive continuous AI development.
* Application level: GenAI games, Ai coated films [5]
* More data centers →  safety governance concerns [5]
* AI marginal costs rise, but Agent efficiency improvements shift SaaS valuation logic to model usage efficiency.  [7]
* accelerate human-machine collaborative learning, redefine labor, enhance productivity  [7]
* enable local GPT-level model-running consumer devices, ushering in the “Intelligent Partner” era. (portable GPT-level model terminals may emerge, enabling offline operation.)  [7]
* AI will redefine labor, with organizations relying on Agents to boost output rather than merely expanding human resources.  [7]
* Data: High-quality text data is saturated, but multimodal data and synthetic data will drive growth.
* Professional data availability is critical for AI reliability, workflow integration, and cost reduction. [13]
* Workflow Integration: Seamless integration with business processes requires high-quality data. [13]
* Compute is the core driver, with algorithms and data supporting scalability. [13]


## Key technology evolution in 2026 
Short-Term Path: Silicon Valley’s “compute + data” competition, pursuing product implementation and commercial value. [18]
### Post-training and fine-tuning
#### Reinforcement Learning: 
Transitioning from supervised fine-tuning (SFT) and RLHF (human feedback reinforcement learning) to the “rubrics & verifiers” stage, ultimately aiming for dynamic simulation environments (RL Environments) and Reinforcement Learning from Human Feedback (RLVR), where AI learns to solve real-world problems in complex, uncertain virtual worlds - must adapt to the chaos and ambiguity of the real world, Not just adapt to maths competitions
  
#### Low Fine-Tuning Usage: 
Only 13.8% of enterprises due to high fine-tuning thresholds (training resources, data annotation), prompt engineering+RAG are more favored compared to fine-tuning [1]      
* only 20.8% fine-tune open-source models, [5]
* 45.9% of respondents plan to increase fine-tuning efforts within 12 months, 23.5% have already heavily fine-tuned models. [5]

#### self-built models: 
a third of enterprises choose self-built models mainly for cost optimization (high usage scenarios), data compliance (cross-border data restrictions), and customization needs.    
* 15.4% build models from scratch. [5]

#### Evaluation: 
hybrid of offline and online (52%+37%), hybrid of human review and LLM-judge (59%+53%)


### Agentic AI 
* AI Agent Explosion, retail, ads, independently complete scientific discoveries (from hypothesis to paper publication).   - 2026 prediction [5]
* Agents replacing traditional logic layers), 
* redefining SaaS industry valuation logic (from subscription numbers to model efficiency), and redefining the concept of “software.”

### Vibe coding 
The industry is shifting focus from coding to management, supervision, and strategic thinking. [20]  


## Reacting to vibe coding by AI
AI code generation is at the forefront of innovation, with competition centered on enhancing model capabilities and optimizing developer experiences. [14]
* Cursor’s Differentiation Strategy: Cursor maintains a leading position by re-designing IDEs (Integrated Development Environments) to create “AI-native” workflows, rather than simply embedding AI as an add-on in traditional IDEs. This innovation allows it to stay ahead in the industry.
* Importance of Multi-Model Choice:developer tools should provide multi-model selection options, allowing users to freely switch between models (e.g., GPT-3.5, Claude Sonnet) rather than being dictated by the platform. This philosophy has become a key factor in competition within the AI programming field.
* Growing Demand for Developers: Software development will only increase, along with the number of developers, driving continuous iteration of tools and platforms.
* Uncertainty in Technological Evolution: The AI programming field is highly competitive and technologically fast-paced, with model capabilities (e.g., Claude Sonnet, Llama series) and industry landscapes potentially changing rapidly.
* Collaboration Between Tools and Developers: Anthropic’s Claude Sonnet leads in coding due to its training in “tool usage,” enabling models to reasonably call various tools (e.g., installing NPM packages) like developers. This capability has become central to the Agent model.     

AI has become the first point of consultation for team members, handling routine issues (e.g., syntax queries, basic algorithms), while complex problems (e.g., system architecture design) still require human collaboration. [20]    
* Deep Skill Atrophy: Relying on AI to solve problems reduces opportunities to learn through reading documentation and debugging complex systems.
* Supervision Paradox: Effective supervision of AI outputs requires coding skills, but over-reliance on AI may lead to skill degradation, creating a vicious cycle.
* Core Skills Retained: Core coding abilities remain highly valued; some engineers argue that only non-critical skills (e.g., low-level memory management) are lost.
* Trend Toward Abstraction Software engineering requiring engineers to focus on product design rather than specific implementation.     

### Collaboration model [20]       
* AI as a Collaborative Partner: Developers view AI as an instantly available “colleague” for brainstorming ideas and quickly validating solutions.
* Human Collaboration Focused on Strategy: Team members increasingly engage in complex decision-making and context-dependent discussions, reducing communication costs for routine issues.
* using AI in education but not relying on it as a question-answering tool, should gradually introducing complexity (e.g., using binary lookup tables to explain language models) to spark users’ initiative. [9]


### Engineer’s role [20]
* From Coders to Managers: code review, revision, and supervising AI outputs, rather than writing new code.
* Multi-AI Coordination: run multiple Claude instances simultaneously to manage different AI workflows - requiring stronger supervision and guidance skills.
* future career trajectories remain unpredictable.
* Adaptation strategy:      
(a) Specialization: Cultivate skills to review AI outputs.    
(b) Strategic Thinking: Focus on interpersonal collaboration and strategic decisions, allowing AI to handle execution.     
(c) Career Development: Use AI to gain leadership feedback and break through growth limits.    

### Mitigation Strategies [20]
* Active Learning: Use AI tools to accelerate learning while maintaining hands-on practice.    
* Adapt to Change: Accept the shift from “executors” to “managers,” cultivating cross-domain collaboration skills.     
* Maintain Flexibility: In a rapidly changing industry, adaptability and continuous learning are core competencies.    


## AGI long term evolution    
Large World Model (LWM)       
### I-JEPA: A Human-Like world Model [21]    
Paper: “A Path Towards Autonomous Machine Intelligence” by Yann LeCun (referenced as the foundation for I-JEPA’s design).      
#### JEPA Overview:
* V-JEPA and I-JEPA: By learning abstract representations of the intrinsic structures of videos and images, they can identify abnormal scenarios and enable reasoning and planning.      
* I-JEPA (Image-based Joint-Embedding Predictive Architecture), a novel computer vision model from Meta AI that aligns with Yann LeCun’s vision for human-like AI. The model addresses limitations in traditional self-supervised learning by predicting missing information in abstract representation spaces, avoiding reliance on data augmentation. It uses three components—a context encoder, target encoder, and predictor—to generate semantic embeddings without explicit labels, enabling robust downstream tasks.     
(a) First AI model based on Yann LeCun’s vision for human-like intelligence, outlined in his 2023 paper “A Path Towards Autonomous Machine Intelligence.”       
(b) Designed for self-supervised learning, eliminating the need for labeled data.      
* Non-Generative Architectures: Unlike traditional self-supervised learning, V-JEPA improves physical common-sense understanding by predicting complete video representations rather than reconstructing inputs.       
#### Self-Supervised Learning Approaches:      
* Invariance-based: Uses data augmentation (e.g., rotations) to train encoders to produce similar embeddings for similar images. Limited to images and requires prior knowledge.
* Generative: Masks parts of images and trains models to reconstruct them, generalizing to text (e.g., LLMs) but achieving lower semantic levels.     
#### I-JEPA’s Innovation:      
* Predicts missing information in abstract representation space (e.g., semantic concepts like “cat leg” rather than pixel details).    
* Uses context blocks (larger patches) and target blocks (smaller patches) to train the model to infer missing semantic features.    
* Avoids data augmentation by relying on mask tokens and predictor models to reconstruct target embeddings.    
#### Architecture Components:    
* Context Encoder: Processes input patches to generate context representations.    
* Target Encoder: Produces patch-level embeddings for target blocks.    
* Predictor: Uses context and mask tokens to predict target embeddings, minimizing L2 distance loss.    
* Training: Context encoder and predictor learn via loss, while target encoder parameters are updated via exponential moving average.    
#### Results:    
* Generates highly semantic representations, enabling strong performance in downstream tasks.    
* Focuses on high-level semantics, reducing errors from insignificant pixel details.    

### Spatial Intelligence is AI’s Next Frontier[22]
#### Overview   
* a capability to understand and interact with the physical world through spatial reasoning. rooted in Alan Turing’s vision of AI as a tool to augment human creativity
* current AI systems lack fundamental understanding of physical commonsense and spatial laws, which are critical for advancing AI beyond text-based tasks
* the next decade’s AI progress will focus on spatial intelligence rather than text processing alone.      
#### Applications 
* Creativity: Tools enabling 3D narrative worlds, immersive design, and real-time adjustments.
* Robotics: Robots as collaborative partners with spatial understanding (e.g., navigating, manipulating objects, interacting with humans).
* Scientific Research: Simulating complex systems (e.g., climate dynamics, atomic structures, galaxy evolution) to accelerate discovery.
* Healthcare: Enhancing drug development, diagnostics, and patient care through spatial analytics.
* Education: Revolutionizing learning with immersive, interactive experiences that replace rote memorization with active exploration.

#### Historical examples
* Eratosthenes calculated Earth’s circumference using geometric spatial reasoning.
* Hargreaves invented the spinning jenny, revolutionizing textile manufacturing through spatial mechanics.
vWatson and Crick discovered DNA’s double-helix structure, relying on spatial visualization.
* These examples underscore that spatial intelligence is foundational to human creativity and scientific discovery.
#### Core Capabilities for World Models
* Generative: Create and maintain consistent 3D environments.
* Multimodal: Integrate spatial, temporal, and sensory data (e.g., vision, touch, motion).
* Spatial Memory: Store and recall spatial relationships (e.g., object positions, properties). tools like the Marble platform, which allows creators to generate and interact with 3D environments using text and sketches.
#### Challenges in World Model Research:
* Training Task Design: Unlike text-based models (e.g., language models predicting next tokens), world models require tasks reflecting physical and geometric laws (e.g., predicting next world states).
* Data Acquisition: Real-world data is sparse and lacks depth/physical attributes, while synthetic data may diverge from reality.
* Model Architecture: Current Transformer-based models struggle with 3D spatial and temporal continuity. Li Fei-Fei proposes innovations like 3D/4D tokenization and spatial memory mechanisms (e.g., the RTFM model, which stores spatial frames for consistency).

### Super Intelligence from Experience [20]
#### Overview    
OaK Architecture (Option and Model Learning) a conceptual framework and research paradigm aimed at building an open, self-improving superintelligent system through runtime experience and autonomous learning.    
* Replace traditional supervised learning dependent on human labels with autonomous exploration based on experience.
* Address challenges of continual learning and meta-learning, enabling agents to dynamically adapt to new tasks and environments.
* Achieve cognitive leaps from low-level experience to high-level abstractions, ultimately forming an infinitely scalable ladder of intelligent growth.
#### Implications for AI Research
* Shift to Experience-Driven Learning: Emphasizes perception and learning through exploration rather than labels, challenging current data-centric and parameter-scale competitions.
* Autonomous Cognitive Construction: Concepts, reasoning, and planning emerge from feature abstraction during subtask solving, not pre-defined rules.
#### OaK operates through an everlasting learning cycle, decomposing the agent’s learning process into five key steps:
1. Feature Construction (Perception)
* The agent extracts state features from raw data (observations and actions) for decision-making and learning.
* The value of features depends on their ability to solve practical problems, not on approximating human-defined labels.
2. Subtask Generation
* When the agent discovers interesting features, it converts them into subtask goals (e.g., “explore sounds”).
* Subtasks must balance main task rewards (e.g., survival) with subgoal achievement, avoiding destructive behaviors (e.g., cliff jumping).
3. Option Learning
* Reinforcement learning generates policies (Options) for each subtask, such as “ring a bell” corresponding to specific action sequences and termination conditions.
* Options, as high-level abstractions, can compose to execute complex tasks (e.g., “walk to the door → open the door”).
4. Model Learning
* For each Option, the agent learns a high-level world model predicting new states, rewards, and environmental changes after execution.
* Models abstract behavioral fragments (not single-step actions), enhancing planning efficiency.
5. Planning
* Based on Options and models, the agent performs long-term strategy planning, such as simulating consequences of multi-step option combinations.
* Planning essentially involves dynamically updating value functions, enabling agents to adapt to changes in main tasks (e.g., reward adjustments).
#### Feedback Mechanism:
Information generated during learning (e.g., some features are more effective, some Option models are more accurate) feeds back to the feature construction module, guiding the agent to build better features and initiating a new cycle.


## Human and AGI relation: ethical challenges 
* Ethical Boundaries: Caution is needed regarding AI-generated content’s copyright and authenticity issues. [12]
* Human’s role should be “objective function designer,” defining AI’s values (e.g., whether an educational AI aims to improve exam scores or foster curiosity).
* AI and human complementary rather than substitutive. [12]
* AI should be a “tool” rather than an “opponent,” focusing on how to assist humans rather than surpass them.
* AI and human intelligence are complementary rather than substitutive, and warns against the flawed assumption that “who reaches whom’s level.” [12]
* AGI possesses the core principle of “technology serving humanity.” [12]
* AI must serve humans rather than deviate from its purpose [16]
* AI’s goal is to enhance human capabilities rather than replace them, and should focus on practical applications (e.g., healthcare, engineering) [16]
* AI and human intelligence are complementary rather than substitutive, and warns against the flawed assumption that “who reaches whom’s level.” [16]
* AI’s true value lies in enhancing human capabilities rather than merely pursuing “superiority over humans.” [16]
* setting core values (e.g., AI not harming humans) to ensure technology benefits humanity, [17]
* AI inheriting human power is an inevitable trend, but democratic governance and value guidance are needed to prevent disasters caused by technological monopoly. [19]
* AI may trap humans in passive, ignorant states, stressing we must preserve humans’ “self-actualization” value rather than merely serving as a survival tool. [9]