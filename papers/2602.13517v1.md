The document presents a detailed analysis of measuring **LLM reasoning** through the concept of **Deep-Thinking Ratio (DTR)**, which quantifies the proportion of tokens in a model's output that reflect "deep thinking" rather than superficial or repetitive responses. Below is a structured summary and analysis of the key points:

---

### **Key Concepts and Methodology**
1. **DTR (Deep-Thinking Ratio)**:
   - **Definition**: DTR is calculated as the ratio of "deep-thinking tokens" (tokens that contribute meaningful reasoning) to the total number of generated tokens.
   - **Purpose**: To evaluate how much a model's output relies on internal reasoning rather than rote generation or redundancy.
   - **Correlation with Accuracy**:
     - The paper compares DTR across three distance metrics: **cosine similarity**, **KL divergence**, and **JS divergence** (Figure 6).
     - **JS divergence** shows the strongest correlation with accuracy (e.g., r = 0.937 for AIME 2025, r = 0.980 for GPQA), suggesting it is the most effective metric for capturing meaningful reasoning.

2. **Think@n Approach**:
   - **Mechanism**: Generates multiple responses (n samples) and selects the best ones using a voting mechanism based on top-ğœ‚ percentage.
   - **Key Findings**:
     - **Number of Samples (n)**: Increasing n improves performance (Figure 8a). For example, Think@48 outperforms Cons@48 (self-consistency) due to a larger candidate pool.
     - **Top-ğœ‚ Percentage**: Optimal performance occurs at ğœ‚ = 50% (Figure 8b). Overly aggressive filtering (ğœ‚ = 25%) or permissive selection (ğœ‚ = 75%) reduces accuracy.
     - **Trade-off**: Too few samples reduce robustness, while too many introduce low-quality responses that dilute Think@n's benefits.

3. **Qualitative Examples**:
   - **Incorrect Output**: Verbose (27,724 tokens), low DTR (13.9), and lacks concise reasoning.
   - **Correct Output**: Concise (3,725 tokens), high DTR (19.0), and aligns with the ground-truth answer (Table 6â€“8).

---

### **Key Results and Implications**
- **DTR as a Metric**: 
  - DTR is **not directly comparable across models** due to varying sequence lengths (longer sequences lower DTR values).
  - Suggests the need for normalization or context-specific benchmarks.
- **Think@n vs. Self-Consistency**:
  - Think@n outperforms self-consistency (Cons@n) by leveraging diverse responses and voting mechanisms.
  - This highlights the importance of **diverse sampling** and **robust selection criteria** in improving model reliability.
- **Model Behavior**:
  - Correct outputs are **concise and high-DTR**, while incorrect outputs are **verbose and low-DTR**, indicating a strong correlation between DTR and reasoning quality.

---

### **Applications and Limitations**
- **Datasets**: Tested on math problems (AIME 2024/2025, HMMT 2025) and GPQA, showing potential for structured reasoning tasks.
- **Limitations**:
  - DTR depends on prompt design and model architecture (e.g., the prompts in Tables 4â€“5 are critical for eliciting reasoning).
  - The metric may not capture all aspects of reasoning (e.g., creativity, multi-step problem-solving).

---

### **Conclusion**
The paper introduces DTR as a novel metric to evaluate LLM reasoning, supported by empirical evidence showing its correlation with accuracy. The Think@n approach, which balances sampling diversity and selection quality, improves performance in tasks requiring structured reasoning. However, the results emphasize the need for careful normalization, prompt engineering, and context-aware benchmarks to fully leverage DTR for model evaluation.

Would you like a deeper dive into a specific section (e.g., methodology, results, or implications)?

===============

## ä¸­æ–‡ç¿»è¯‘

æ–‡æ¡£è¯¦ç»†åˆ†æäº†é€šè¿‡**æ·±åº¦æ€è€ƒæ¯”ä¾‹ï¼ˆDTRï¼‰**æ¦‚å¿µè¡¡é‡**LLMæ¨ç†**çš„æ–¹æ³•ï¼Œè¯¥æŒ‡æ ‡é‡åŒ–äº†æ¨¡å‹è¾“å‡ºä¸­åæ˜ â€œæ·±åº¦æ€è€ƒâ€è€Œéè¡¨é¢åŒ–æˆ–é‡å¤æ€§å›åº”çš„tokenæ¯”ä¾‹ã€‚ä»¥ä¸‹æ˜¯å…³é”®è¦ç‚¹çš„ç»“æ„åŒ–æ€»ç»“ä¸åˆ†æï¼š

---

### **å…³é”®æ¦‚å¿µä¸æ–¹æ³•**
1. **DTRï¼ˆæ·±åº¦æ€è€ƒæ¯”ä¾‹ï¼‰**ï¼š
   - **å®šä¹‰**ï¼šDTRæ˜¯â€œæ·±åº¦æ€è€ƒtokenâ€ï¼ˆè´¡çŒ®æœ‰æ„ä¹‰æ¨ç†çš„tokenï¼‰ä¸ç”Ÿæˆæ€»tokenæ•°çš„æ¯”ä¾‹ã€‚
   - **ç›®çš„**ï¼šè¯„ä¼°æ¨¡å‹è¾“å‡ºä¾èµ–å†…éƒ¨æ¨ç†çš„ç¨‹åº¦ï¼Œè€Œéæœºæ¢°ç”Ÿæˆæˆ–å†—ä½™ã€‚
   - **ä¸å‡†ç¡®ç‡çš„ç›¸å…³æ€§**ï¼š
     - æ–‡æ¡£å¯¹æ¯”äº†ä¸‰ç§è·ç¦»åº¦é‡ä¸‹çš„DTRï¼š**ä½™å¼¦ç›¸ä¼¼åº¦**ã€**KLæ•£åº¦**å’Œ**JSæ•£åº¦**ï¼ˆå›¾6ï¼‰ã€‚
     - **JSæ•£åº¦**ä¸å‡†ç¡®ç‡ç›¸å…³æ€§æœ€å¼ºï¼ˆä¾‹å¦‚AIME 2025çš„r=0.937ï¼ŒGPQAçš„r=0.980ï¼‰ï¼Œè¡¨æ˜å…¶æ˜¯æ•æ‰æœ‰æ„ä¹‰æ¨ç†çš„æœ€æœ‰æ•ˆæŒ‡æ ‡ã€‚

2. **Think@næ–¹æ³•**ï¼š
   - **æœºåˆ¶**ï¼šç”Ÿæˆå¤šä¸ªå“åº”ï¼ˆnä¸ªæ ·æœ¬ï¼‰ï¼Œå¹¶é€šè¿‡åŸºäºå‰ğœ‚ç™¾åˆ†æ¯”çš„æŠ•ç¥¨æœºåˆ¶é€‰æ‹©æœ€ä½³å“åº”ã€‚
   - **å…³é”®å‘ç°**ï¼š
     - **æ ·æœ¬æ•°é‡ï¼ˆnï¼‰**ï¼šå¢åŠ nå¯æå‡æ€§èƒ½ï¼ˆå›¾8aï¼‰ã€‚ä¾‹å¦‚ï¼ŒThink@48å› å€™é€‰æ± æ›´å¤§ï¼Œä¼˜äºCons@48ï¼ˆè‡ªæ´½æ€§ï¼‰ã€‚
     - **å‰ğœ‚ç™¾åˆ†æ¯”**ï¼šæœ€ä½³æ€§èƒ½å‡ºç°åœ¨ğœ‚=50%ï¼ˆå›¾8bï¼‰ã€‚è¿‡åº¦ç­›é€‰ï¼ˆğœ‚=25%ï¼‰æˆ–å®½æ¾é€‰æ‹©ï¼ˆğœ‚=75%ï¼‰ä¼šé™ä½å‡†ç¡®ç‡ã€‚
     - **æƒè¡¡**ï¼šæ ·æœ¬è¿‡å°‘ä¼šé™ä½é²æ£’æ€§ï¼Œè¿‡å¤šåˆ™å¼•å…¥ä½è´¨é‡å“åº”ï¼Œç¨€é‡ŠThink@nçš„ä¼˜åŠ¿ã€‚

3. **å®šæ€§ç¤ºä¾‹**ï¼š
   - **é”™è¯¯è¾“å‡º**ï¼šå†—é•¿ï¼ˆ27,724ä¸ªtokenï¼‰ï¼ŒDTRä½ï¼ˆ13.9ï¼‰ï¼Œç¼ºä¹ç®€æ´æ¨ç†ã€‚
   - **æ­£ç¡®è¾“å‡º**ï¼šç®€æ´ï¼ˆ3,725ä¸ªtokenï¼‰ï¼ŒDTRé«˜ï¼ˆ19.0ï¼‰ï¼Œä¸çœŸå®ç­”æ¡ˆä¸€è‡´ï¼ˆè¡¨6â€“8ï¼‰ã€‚

---

### **å…³é”®ç»“æœä¸å¯ç¤º**
- **DTRä½œä¸ºæŒ‡æ ‡**ï¼š
  - ç”±äºåºåˆ—é•¿åº¦å·®å¼‚ï¼ŒDTR**æ— æ³•ç›´æ¥è·¨æ¨¡å‹æ¯”è¾ƒ**ï¼ˆæ›´é•¿åºåˆ—å¯¼è‡´æ›´ä½çš„DTRå€¼ï¼‰ã€‚
  - å»ºè®®é‡‡ç”¨å½’ä¸€åŒ–æˆ–ä¸Šä¸‹æ–‡ç‰¹å®šåŸºå‡†ã€‚
- **Think@n vs. è‡ªæ´½æ€§**ï¼š
  - Think@né€šè¿‡å¤šæ ·åŒ–å“åº”å’ŒæŠ•ç¥¨æœºåˆ¶ä¼˜äºè‡ªæ´½æ€§ï¼ˆCons@nï¼‰ã€‚
  - è¿™çªæ˜¾äº†**å¤šæ ·åŒ–é‡‡æ ·**å’Œ**ç¨³å¥é€‰æ‹©æ ‡å‡†**åœ¨æå‡æ¨¡å‹å¯é æ€§ä¸­çš„é‡è¦æ€§ã€‚
- **æ¨¡å‹è¡Œä¸º**ï¼š
  - æ­£ç¡®è¾“å‡º**ç®€æ´ä¸”é«˜DTR**ï¼Œé”™è¯¯è¾“å‡º**å†—é•¿ä¸”ä½DTR**ï¼Œè¡¨æ˜DTRä¸æ¨ç†è´¨é‡å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚

---

### **åº”ç”¨ä¸å±€é™æ€§**
- **æ•°æ®é›†**ï¼šåœ¨æ•°å­¦é—®é¢˜ï¼ˆAIME 2024/2025ã€HMMT 2025ï¼‰å’ŒGPQAä¸Šæµ‹è¯•ï¼Œå±•ç¤ºäº†å…¶åœ¨ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚
- **å±€é™æ€§**ï¼š
  - DTRä¾èµ–äºæç¤ºè®¾è®¡å’Œæ¨¡å‹æ¶æ„ï¼ˆä¾‹å¦‚è¡¨4â€“5ä¸­çš„æç¤ºå¯¹å¼•å‘æ¨ç†è‡³å…³é‡è¦ï¼‰ã€‚
  - è¯¥æŒ‡æ ‡å¯èƒ½æ— æ³•å…¨é¢æ•æ‰æ¨ç†çš„å„ä¸ªæ–¹é¢ï¼ˆå¦‚åˆ›é€ åŠ›ã€å¤šæ­¥éª¤é—®é¢˜è§£å†³ï¼‰ã€‚

---

### **ç»“è®º**
æœ¬æ–‡å¼•å…¥DTRä½œä¸ºè¯„ä¼°LLMæ¨ç†çš„æ–°é¢–æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡å®è¯æ•°æ®æ”¯æŒå…¶ä¸å‡†ç¡®ç‡çš„ç›¸å…³æ€§ã€‚Think@næ–¹æ³•é€šè¿‡å¹³è¡¡é‡‡æ ·å¤šæ ·æ€§å’Œé€‰æ‹©è´¨é‡ï¼Œåœ¨éœ€è¦ç»“æ„åŒ–æ¨ç†çš„ä»»åŠ¡ä¸­æå‡äº†æ€§èƒ½ã€‚ç„¶è€Œï¼Œç»“æœå¼ºè°ƒéœ€è°¨æ…å½’ä¸€åŒ–ã€æç¤ºå·¥ç¨‹åŠä¸Šä¸‹æ–‡æ„ŸçŸ¥åŸºå‡†ï¼Œä»¥å……åˆ†å‘æŒ¥DTRåœ¨æ¨¡å‹è¯„ä¼°ä¸­çš„ä½œç”¨ã€‚

æ˜¯å¦éœ€è¦æ·±å…¥æ¢è®¨æŸä¸€å…·ä½“éƒ¨åˆ†ï¼ˆä¾‹å¦‚æ–¹æ³•ã€ç»“æœæˆ–å¯ç¤ºï¼‰ï¼Ÿ

#### Reference: 

Source file: 2602.13517v1.pdf

---

**Title**: Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens

**Authors & Affiliations**: **baselines. Leveraging this insight, we introduce Think@** _ğ‘›_ **, a test-time scaling strategy that prioritizes** **samples with high deep-thinking ratios. We demonstrate that Think@** _ğ‘›_ **matches or exceeds standard**
