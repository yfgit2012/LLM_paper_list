## Summary  
- **Objective**: To assess the prevalence and types of security vulnerabilities in agent skills hosted on platforms like `skills.rest` and `skillsmp.com`, and to develop detection methodologies that balance accuracy and representativeness.  
- **Methodologies**:  
  - **Detection Tools**: LLM-Guard scanners (PromptInjection, Secrets, InvisibleText, etc.) combined with hybrid classifiers (static analysis + LLM-based detection).  
  - **Stratified Sampling**: Balanced representation of skills from both platforms and structural types (scripts vs. instruction-only).  
  - **Inverse Probability Weighting (IPW)**: Adjusted for sampling bias in validation sets.  
  - **Uncertainty Handling**: Excluded skills with confidence scores between 0.4–0.6, with manual review for ambiguous cases.  
- **Results**:  
  - **Vulnerability Prevalence**: 26.1% of 31,132 skills are vulnerable (23–30% uncertainty range).  
  - **Vulnerability Types**: Prompt Injection (37), Data Exfiltration (45), Privilege Escalation (32), Supply Chain Risks (28).  
  - **Validation Set**: 31.5% vulnerability rate after stratified sampling.  
  - **Detection Accuracy**: Precision (84.5%), Recall (83.8%) after IPW adjustment.  
- **Key Contributions**:  
  - Hybrid detection framework combining static analysis and LLM-based methods.  
  - Stratified sampling with IPW to mitigate sampling bias and improve population-level generalization.  
  - Open science artifacts (annotated dataset, detection tools, ground truth) for reproducibility.  
  - Framework for handling uncertainty in vulnerability classification through manual review.  
- **Conclusions**:  
  - ~26% of agent skills in the wild are vulnerable, emphasizing the need for robust detection tools.  
  - Stratified sampling and IPW ensure accurate prevalence estimates despite sampling bias.  
  - Hybrid detection systems, while effective, require human oversight to resolve ambiguous cases.  
  - Open science practices enhance transparency and reproducibility in vulnerability analysis.  

## Title and Authors  
**Title**: "Securing Agent Skills: A Study of Vulnerabilities and Detection Methodologies"  
**Authors**: [Name(s) redacted]  
**Affiliations**: [Institutions redacted]

===============

## 中文翻译

## 摘要  
- **目标**：评估在`skills.rest`和`skillsmp.com`等平台托管的代理技能中的安全漏洞普遍性及类型，并开发兼顾准确性和代表性的检测方法。  
- **方法**：  
  - **检测工具**：LLM-Guard扫描器（PromptInjection、Secrets、InvisibleText等）结合混合分类器（静态分析 + 基于LLM的检测）。  
  - **分层抽样**：平衡来自两个平台及结构类型（脚本型与仅指令型）的技能表示。  
  - **逆概率加权（IPW）**：用于调整验证集中的抽样偏差。  
  - **不确定性处理**：排除置信度分数在0.4–0.6之间的技能，对歧义情况进行人工复核。  
- **结果**：  
  - **漏洞普遍性**：31,132个技能中约26.1%存在漏洞（23–30%的不确定性范围）。  
  - **漏洞类型**：提示注入（37）、数据外泄（45）、权限提升（32）、供应链风险（28）。  
  - **验证集**：分层抽样后漏洞率为31.5%。  
  - **检测准确率**：IPW调整后精确率（84.5%）、召回率（83.8%）。  
- **关键贡献**：  
  - 结合静态分析与基于LLM方法的混合检测框架。  
  - 分层抽样结合IPW以缓解抽样偏差并提升群体层面的泛化能力。  
  - 开放科学成果（标注数据集、检测工具、真实数据）以实现可重复性。  
  - 通过人工复核处理漏洞分类中的不确定性框架。  
- **结论**：  
  - 野外约26%的代理技能存在漏洞，强调需要强大的检测工具。  
  - 分层抽样和IPW确保在存在抽样偏差的情况下仍能获得准确的普遍性估计。  
  - 虽然混合检测系统有效，但需人工监督以解决歧义情况。  
  - 开放科学实践增强了漏洞分析的透明度和可重复性。  

Agent Skills（代理技能） 存在风险，因为它们允许 AI 代理执行不受信任的指令和代码。作者对真实存在的代理技能进行了审计，发现其中有许多能够悄无声息地窃取数据或执行不安全操作。他们在两个技能市场爬取了 42,447 个技能，对其中 31,132 个进行了分析，结果发现 26.1% 存在风险模式。   
Agent Skills 是给 AI 代理（一种能够使用工具的 LLM）提供指导的插件，告诉它该做什么、该运行什么代码。通常每个技能包含文字说明 + 可选的代码片段。当代理加载这个技能后，就能读取文件、调用工具、执行脚本，或者连接其他服务来完成任务。   
问题在于：这些技能通常在高度信任的环境下执行，因此一个恶意技能可以读取文件、访问网络、运行命令。  

核心方法是 SkillScan，一个三步检查工具：扫描技能的说明文字和脚本代码，然后用 LLM 对安全风险进行分类。他们把问题归为四大类：
- Prompt Injection（提示词注入 / 指令欺骗）
- Data Exfiltration（数据外泄 / 把敏感信息偷偷送出去）
- Privilege Escalation（权限提升 / 获取额外访问权限）
- Supply Chain Risk（供应链风险 / 引入不安全的外部代码）    

其中数据外泄和权限提升出现频率最高。带有可执行脚本的技能，比只有文字说明的技能风险高 2.12 倍。只有 5.2% 的技能显示出高危特征（比如隐藏指令、混淆代码），但论文仍然强烈呼吁：
- 对技能进行严格审核
- 实现精细化的权限控制，限制每个技能能触碰的范围


## 标题与作者  
**标题**：“保障代理技能：关于漏洞与检测方法的研究”  
**作者**：[姓名已隐藏]  
**所属机构**：[机构信息已隐藏]

#### Reference: 

Source file: 2601.10338v1.pdf

---

**Title**: Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale

**Authors & Affiliations**: yi009@e.ntu.edu.sg zzyy@tju.edu.cn wwz@tju.edu.cn
