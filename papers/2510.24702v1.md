The document outlines strategies for training AI agents using large language models (LLMs), focusing on **data balancing** and **domain-specific filtering** to optimize performance across different tasks. Here's a structured breakdown of the key concepts and methodologies:

---

### **A. Use of LLMs for Writing and Presentation**
- **Purpose**: LLMs were used to refine writing style, improve clarity, and enhance LaTeX formatting (e.g., tables, figures).
- **Tasks**: 
  - Polishing wording and tightening paragraphs.
  - Ensuring consistent and professional presentation of technical content.

---

### **B. Data Sampling for Balanced Training**
**Goal**: Balance domain representation and reduce over-representation of certain sources by resampling datasets.

#### **Methodology**
- **Resampling Strategy**: 
  - Each dataset is resampled using a **multiplier `wd`**. 
    - If `wd < 1`: **Downsampling** (e.g., `wd = 0.1` for `code_feedback`).
    - If `wd > 1`: **Upsampling** (e.g., `wd = 3` for `swe-gym`).
  - **Effective Mixture**: The final training data is a weighted combination of datasets, proportional to `wd`, while keeping the overall epoch size stable.
- **Implementation**:
  - Fixed random seed for reproducibility.
  - Shuffled sampled examples across datasets each epoch to avoid bias.

#### **Key Datasets and Multipliers**
| Dataset | `wd` | Direction |
|---------|------|-----------|
| `agenttuning` (various) | 2 | Up |
| `code_feedback` | 0.1 | Down |
| `orca_agentinstruct` | 0.001 | Down |
| `swe-gym` | 3 | Up |
| `swe-smith` | 1 | Neutral |
| `synatra` | 0.01 | Down |

**Note**: Large corpora (e.g., `orca_agentinstruct` at `wd=0.001`) are downsampled, while under-represented datasets (e.g., `swe-gym` at `wd=3`) are upsampled.

---

### **C. Domain-Specific Data Filtering**
**Goal**: Optimize training by aligning data with the evaluation focus of each agent framework.

#### **1. OpenHands and SWE-Agent Training**
- **Focus**: Coding and software engineering tasks (e.g., SWE-Bench, AgentBench OS, GAIA).
- **Data Filtered**: 
  - **Excluded**: Web-browsing datasets (Mind2Web, Go-Browse, NNetNav, Synatra).
  - **Included**: Code generation, software engineering, and API/tool usage datasets.
- **Rationale**: Avoid interference from web-specific interaction patterns (e.g., browser navigation) that are irrelevant to command-line environments.

#### **2. AgentLab Training**
- **Focus**: Web browsing tasks (evaluated on WebArena).
- **Data Filtered**: 
  - **Excluded**: Coding/software engineering datasets.
  - **Included**: Web navigation, browser-based task completion, and web-specific instruction datasets (Mind2Web, Go-Browse, NNetNav, Synatra).
- **Rationale**: Ensure the model is optimized for web browsing patterns and UI interactions without dilution from less relevant domains.

---

### **D. Practical Implementation Details**
- **Random Seed**: Fixed for reproducibility.
- **Shuffling**: Sampled examples are shuffled across datasets each epoch to maintain diversity.
- **Balanced Domains**: The resampling strategy ensures equitable representation of coding, software engineering (SWE), tool-use, and web-browsing tasks.

---

### **Key Takeaways**
1. **Data Balancing**: Resampling with `wd` multipliers ensures no single domain dominates training, while maintaining stable epoch sizes.
2. **Domain-Specific Optimization**: Filtering datasets aligns training data with the evaluation tasks of each agent (e.g., coding vs. web browsing).
3. **Reproducibility**: Fixed random seeds and shuffling ensure consistent results across experiments.

This approach ensures that the model is well-suited for its intended tasks while avoiding biases from irrelevant data sources.

===============

## 中文翻译

### **A. 使用大语言模型进行写作与展示**
- **目的**：利用大语言模型优化写作风格，提升清晰度，并增强LaTeX格式（例如表格、图表）。
- **任务**：
  - 优化措辞并精简段落。
  - 确保技术内容的呈现一致且专业。

---

### **B. 平衡训练的数据采样**
**目标**：平衡领域表示，通过重采样数据集减少某些来源的过度表示。

#### **方法**
- **重采样策略**：
  - 每个数据集使用 **乘数 `wd`** 进行重采样。
    - 若 `wd < 1`：**下采样**（例如 `wd = 0.1` 对应 `code_feedback`）。
    - 若 `wd > 1`：**上采样**（例如 `wd = 3` 对应 `swe-gym`）。
  - **有效混合**：最终训练数据是各数据集的加权组合，比例与 `wd` 相关，同时保持总训练轮次规模稳定。
- **实现**：
  - 固定随机种子以确保可重复性。
  - 每个训练轮次中对数据集的采样示例进行洗牌，以避免偏差。

#### **关键数据集与乘数**
| 数据集 | `wd` | 方向 |
|--------|------|------|
| `agenttuning`（多种） | 2 | 上 |
| `code_feedback` | 0.1 | 下 |
| `orca_agentinstruct` | 0.001 | 下 |
| `swe-gym` | 3 | 上 |
| `swe-smith` | 1 | 中性 |
| `synatra` | 0.01 | 下 |

**说明**：大型语料库（如 `orca_agentinstruct` 在 `wd=0.001` 时）进行下采样，而代表性不足的数据集（如 `swe-gym` 在 `wd=3` 时）进行上采样。

---

### **C. 领域特定数据过滤**
**目标**：通过使训练数据与各智能体框架的评估重点对齐，优化训练效果。

#### **1. OpenHands 和 SWE-Agent 训练**
- **重点**：编码和软件工程任务（如 SWE-Bench、AgentBench OS、GAIA）。
- **过滤数据**：
  - **排除**：网络浏览数据集（Mind2Web、Go-Browse、NNetNav、Synatra）。
  - **包含**：代码生成、软件工程和 API/工具使用数据集。
- **理由**：避免网络特定交互模式（如浏览器导航）对命令行环境的干扰。

#### **2. AgentLab 训练**
- **重点**：网络浏览任务（在 WebArena 上评估）。
- **过滤数据**：
  - **排除**：编码/软件工程数据集。
  - **包含**：网络导航、基于浏览器的任务完成和网络特定指令数据集（Mind2Web、Go-Browse、NNetNav、Synatra）。
- **理由**：确保模型针对网络浏览模式和 UI 交互进行优化，避免无关领域的干扰。

---

### **D. 实践实现细节**
- **随机种子**：固定以确保可重复性。
- **洗牌**：每个训练轮次中对数据集的采样示例进行洗牌，以保持多样性。
- **均衡领域**：重采样策略确保编码、软件工程（SWE）、工具使用和网络浏览任务的均衡表示。

---

### **关键要点**
1. **数据平衡**：通过 `wd` 乘数重采样，确保无单一领域主导训练，同时保持训练轮次规模稳定。
2. **领域特定优化**：过滤数据集使训练数据与各智能体的评估任务对齐（如编码与网络浏览）。
3. **可重复性**：固定随机种子和洗牌操作确保实验结果的一致性。

此方法确保模型适合其预期任务，同时避免无关数据源带来的偏差。

#### Reference: 

Source file: 2510.24702v1.pdf

---

**Title**: Yueqi Song** [1] **, Ketan Ramaneti** [1] **, Zaid Sheikh** [1] **, Ziru Chen** [2] **, Boyu Gou** [2] **, Tianbao Xie** [3] **,

**Authors & Affiliations**: _{_ yueqis,gneubig _}_ @cs.cmu.edu
