## Summary
- **Objective**: To evaluate the effectiveness of Chain-of-Thought (CoT) prompting and self-consistency techniques in improving zero-shot and few-shot performance of machine learning models on complex arithmetic reasoning tasks.  
- **Methodologies**: The study compared Zero-shot, Few-shot, Zero-shot-CoT, and Zero-shot-CoT + Self-Consistency models across datasets like AQUA-RAT, SVAMP, GSM8K, and MultiArith. Self-consistency involved generating multiple reasoning paths (e.g., 40 paths) and selecting majority-voted answers. CoT required explicit step-by-step reasoning.  
- **Results**: Zero-shot-CoT significantly outperformed Zero-shot and Few-shot models (e.g., 63.1% vs. 23.4% on SVAMP). Self-consistency further boosted accuracy (e.g., 89.0% on MultiArith). Larger models (e.g., PaLM 540B) benefited most from CoT and self-consistency, achieving 93.0% on MultiArith with Few-shot-CoT + self-consistency. Smaller models showed limited gains.  
- **Key Contributions**: Demonstrated that CoT and self-consistency enhance zero-shot performance, especially for complex tasks. Highlighted the scalability of these techniques with larger models. Introduced systematic evaluation of CoT and self-consistency across diverse datasets.  
- **Conclusions**: CoT and self-consistency are critical for improving zero-shot reasoning accuracy. Larger models achieve exponential gains with these techniques, suggesting complementary benefits of scaling and reasoning. These methods have practical applications in AI assistants and problem-solving systems.  

## Title and Authors (Required)  
**Title**: *Enhancing Zero-Shot Reasoning via Chain-of-Thought Prompting and Self-Consistency*  
**Authors**: [Authors not provided in the extracted text]  
**Affiliations**: [Affiliations not provided in the extracted text]

===============

## 中文翻译

## 摘要
- **目标**：评估链式思维（CoT）提示和自洽性技术在提升机器学习模型在复杂算术推理任务中的零样本和少样本表现的有效性。  
- **方法**：研究在AQUA-RAT、SVAMP、GSM8K和MultiArith等数据集上比较了零样本、少样本、零样本-CoT和零样本-CoT + 自洽性模型。自洽性涉及生成多个推理路径（例如40条路径）并选择多数投票答案。CoT要求显式的分步推理。  
- **结果**：零样本-CoT显著优于零样本和少样本模型（例如在SVAMP上63.1% vs. 23.4%）。自洽性进一步提升了准确率（例如在MultiArith上达到89.0%）。大模型（例如PaLM 540B）从CoT和自洽性中获益最大，通过少样本-CoT + 自洽性在MultiArith上达到93.0%。小模型的提升有限。  
- **关键贡献**：证明了CoT和自洽性能增强零样本表现，尤其在复杂任务中。突出了这些技术在大模型中的可扩展性。系统性地评估了CoT和自洽性在多样化数据集上的表现。  
- **结论**：CoT和自洽性对提升零样本推理准确率至关重要。大模型通过这些技术实现指数级提升，表明扩展性和推理能力的协同增益。这些方法在AI助手和问题解决系统中具有实际应用价值。  

## 标题和作者（必填）  
**标题**：*通过链式思维提示和自洽性增强零样本推理*  
**作者**：[提取文本中未提供作者信息]  
**所属机构**：[提取文本中未提供所属机构信息]

#### Reference: 

Source file: 2205.11916v4.pdf

---

**Title**: Takeshi Kojima

**Authors & Affiliations**: t.kojima@weblab.t.u-tokyo.ac.jp
