## Summary
- **Objective**: To address the limitations of existing automated metrics (e.g., FID, CLIPScore) by introducing GENEVAL, a framework for fine-grained evaluation of text-to-image (T2I) models through structured analysis of compositional properties like object co-occurrence, position, count, and color.  
- **Methodologies**: GENEVAL integrates object detection (using Mask2Former for instance segmentation) and color classification (via CLIP ViT-L/14) to assess T2I models on structured tasks. It employs binary correctness scoring based on prompt alignment and evaluates six tasks (e.g., counting, position, attribute binding) with template-generated prompts.  
- **Results**: GENEVAL achieves 83% human agreement (outperforming CLIPScore’s 80% and interannotator agreement of 88%). It highlights model-specific failures, such as SDv2.1’s struggles with attribute binding and IF-XL’s position bias. CLIP retrieval underperforms on counting due to out-of-distribution data. Task-specific gaps in spatial reasoning and attribute binding are identified.  
- **Key Contributions**:  
  1. A modular, interpretable framework for evaluating T2I models on compositional tasks.  
  2. Integration of object detection and color classification for fine-grained analysis.  
  3. Identification of failure modes (e.g., spatial reasoning deficits, attribute binding errors) in existing models.  
  4. Public availability for broader use in T2I model evaluation.  
- **Conclusions**: GENEVAL aligns strongly with human judgment and provides actionable insights into T2I model limitations. It underscores the need for improved spatial and attribute-based reasoning in future models. Future work includes leveraging advanced discriminative vision models and enhancing training data diversity.  

## Title and Authors  
**Title**: GENEVAL: A Framework for Fine-Grained Evaluation of Text-to-Image Models  
**Authors**: [Authors’ names and affiliations, if provided in the original document]  
**Affiliations**: [Affiliations, if provided in the original document]

===============

## 中文翻译

## 摘要
- **目标**：通过结构化分析组合属性（如物体共现、位置、数量和颜色），引入GENEVAL框架以解决现有自动指标（如FID、CLIPScore）的局限性，实现对文本到图像（T2I）模型的细粒度评估。  
- **方法**：GENEVAL结合物体检测（使用Mask2Former进行实例分割）和颜色分类（通过CLIP ViT-L/14）来评估T2I模型在结构化任务中的表现。其基于提示对齐的二元正确性评分机制，并利用模板生成提示评估六个任务（如计数、位置、属性绑定）。  
- **结果**：GENEVAL达到83%的人类一致性（优于CLIPScore的80%和标注者间一致性88%）。它揭示了模型特定的失败案例，例如SDv2.1在属性绑定上的困难和IF-XL的位置偏差。由于分布外数据，CLIP检索在计数任务中表现不佳。发现了空间推理和属性绑定任务中的特定差距。  
- **关键贡献**：  
  1. 一个模块化、可解释的框架，用于评估T2I模型在组合任务中的表现。  
  2. 集成物体检测和颜色分类以实现细粒度分析。  
  3. 识别现有模型中的失败模式（如空间推理缺陷、属性绑定错误）。  
  4. 向公众开放以促进T2I模型评估的广泛应用。  
- **结论**：GENEVAL与人类判断高度一致，并提供了对T2I模型局限性的可操作见解。它强调未来模型需改进空间和基于属性的推理能力。未来工作包括利用先进的判别性视觉模型并增强训练数据的多样性。  

## 标题与作者  
**标题**：GENEVAL：文本到图像模型的细粒度评估框架  
**作者**：[原文档中提供的作者姓名及所属机构]  
**所属机构**：[原文档中提供的所属机构]

#### Reference: 

Source file: 2310.11513v1.pdf

---

**Title**: GENEVAL: An Object-Focused Framework for Evaluating Text-to-Image Alignment
