## Summary  
- **Objective**: To develop an efficient active learning framework for neural networks that reduces annotation costs while maintaining model performance by leveraging nonparametric statistics.  
- **Methodologies**: Combines nonparametric techniques (kernel density estimation, local regression) with neural networks to quantify sample informativeness. The proposed algorithm, Nonparametric Active Learning (NAL), uses density estimation, uncertainty quantification, and query selection based on statistical criteria to prioritize informative samples.  
- **Results**: NAL outperforms traditional active learning methods (e.g., uncertainty sampling, random sampling) in accuracy and efficiency, achieving comparable or better performance with fewer labeled samples. Empirical evaluations on benchmark datasets demonstrate its effectiveness in reducing annotation costs without sacrificing model quality.  
- **Key Contributions**:  
  1. Introduces a nonparametric framework for active learning, contrasting with heuristic-based methods.  
  2. Provides theoretical guarantees linking active learning to nonparametric risk bounds.  
  3. Proposes the NAL algorithm, integrating neural networks with nonparametric statistical tools.  
  4. Bridges active learning with nonparametric statistical learning theory, offering a statistically rigorous approach.  
- **Conclusions**: The paper presents a theoretically sound and practically effective method for active learning in neural networks, demonstrating the value of combining nonparametric statistics with deep learning to achieve data-efficient, high-performance models.  

## Title and Authors  
**Title**: Active Learning with Neural Networks: Insights from Nonparametric Statistics  
**Authors**: Yinglun Zhu, Robert Nowak  
**Affiliations**: University of Wisconsin-Madison (Zhu), University of Wisconsin-Madison (Nowak)

===============

## 中文翻译

## 摘要  
- **目标**：开发一种高效的主动学习框架，利用非参数统计方法在降低标注成本的同时保持模型性能。  
- **方法**：将非参数技术（核密度估计、局部回归）与神经网络结合，量化样本信息量。提出的算法“非参数主动学习”（NAL）通过基于统计准则的密度估计、不确定性量化及查询选择，优先获取信息量大的样本。  
- **结果**：NAL在准确性和效率上超越传统主动学习方法（如不确定性采样、随机采样），在使用更少标注样本的情况下实现可比或更优的性能。在基准数据集上的实证评估表明，其在降低标注成本的同时不牺牲模型质量。  
- **关键贡献**：  
  1. 引入一种非参数主动学习框架，与基于启发式的方法形成对比。  
  2. 提供将主动学习与非参数风险界限联系起来的理论保证。  
  3. 提出NAL算法，将神经网络与非参数统计工具相结合。  
  4. 将主动学习与非参数统计学习理论相衔接，提供一种统计严谨的方法。  
- **结论**：本文提出了一种在理论上严谨且实践中有效的神经网络主动学习方法，展示了结合非参数统计与深度学习在实现高效数据利用和高性能模型方面的价值。  

## 标题与作者  
**标题**：基于非参数统计的神经网络主动学习：见解  
**作者**：Zhu Yinglun, Nowak Robert  
**单位**：威斯康星大学麦迪逊分校（Zhu），威斯康星大学麦迪逊分校（Nowak）

#### Reference: 

Source file: 2602.17985v1.pdf

---

**Title**: Committee Approval
